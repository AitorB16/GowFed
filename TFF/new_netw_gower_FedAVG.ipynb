{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 06:47:27.444162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-27 06:47:27.444190: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tester/Desktop/TF/TFF', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/home/tester/venv/lib/python3.9/site-packages', '/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg', '/home/tester/Desktop/TF/gower/gower', '/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "import collections\n",
    "\n",
    "from absl import app\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "\n",
    "from keras.backend import print_tensor\n",
    "\n",
    "#import gower\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg\")\n",
    "sys.path.append(\"/home/tester/Desktop/TF/gower/gower\")\n",
    "#print(sys.path)\n",
    "import simple_fedavg_tff\n",
    "import gower_dist as gd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "TOTAL_ROUNDS = 500 #NUMBER OF TOTAL TRAINING ROUNDS\n",
    "ROUNDS_PER_EVAL = 1 #HOW OFTEN TO EVALUATE\n",
    "TRAIN_CLIENTS_PER_ROUND = 3 #HOW MANY CLIENTS TO SAMPLE PER ROUND\n",
    "CLIENT_EPOCHS_PER_ROUND = 2 #NUMBER OF EPOCHS IN THE CLIENT TO TAKE PER ROUND\n",
    "BATCH_SIZE = 64 #BATCH SIZE USED ON THE CLIENT\n",
    "TEST_BATCH_SIZE = 32 #MINIBATCH SIZE OF TEST DATA\n",
    "SERVER_LEARNING_RATE = 0.0001 #SERVER LEARNING RATE\n",
    "CLIENT_LEARNING_RATE = 0.00001 #CLIENT LEARNING RATE\n",
    "NUM_CLIENTS = 12\n",
    "\n",
    "TRAIN_SIZE = 6500\n",
    "TEST_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>...</th>\n",
       "      <th>http_request_body_len</th>\n",
       "      <th>http_response_body_len</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>http_user_agent</th>\n",
       "      <th>http_orig_mime_types</th>\n",
       "      <th>http_resp_mime_types</th>\n",
       "      <th>weird_name</th>\n",
       "      <th>weird_addl</th>\n",
       "      <th>weird_notice</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.122.49.24</td>\n",
       "      <td>1883</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>52976</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>80549.530260</td>\n",
       "      <td>1762852</td>\n",
       "      <td>41933215</td>\n",
       "      <td>OTH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_TCP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>47260</td>\n",
       "      <td>192.168.1.255</td>\n",
       "      <td>15600</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>1880</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>51782</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_TCP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>34296</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>10502</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>46608</td>\n",
       "      <td>192.168.1.190</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>SHR</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_UDP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          src_ip  src_port         dst_ip  dst_port proto service  \\\n",
       "0    3.122.49.24      1883  192.168.1.152     52976   tcp       -   \n",
       "1   192.168.1.79     47260  192.168.1.255     15600   udp       -   \n",
       "2  192.168.1.152      1880  192.168.1.152     51782   tcp       -   \n",
       "3  192.168.1.152     34296  192.168.1.152     10502   tcp       -   \n",
       "4  192.168.1.152     46608  192.168.1.190        53   udp     dns   \n",
       "\n",
       "       duration  src_bytes  dst_bytes conn_state  ...  http_request_body_len  \\\n",
       "0  80549.530260    1762852   41933215        OTH  ...                      0   \n",
       "1      0.000000          0          0         S0  ...                      0   \n",
       "2      0.000000          0          0        OTH  ...                      0   \n",
       "3      0.000000          0          0        OTH  ...                      0   \n",
       "4      0.000549          0        298        SHR  ...                      0   \n",
       "\n",
       "   http_response_body_len  http_status_code  http_user_agent  \\\n",
       "0                       0                 0                -   \n",
       "1                       0                 0                -   \n",
       "2                       0                 0                -   \n",
       "3                       0                 0                -   \n",
       "4                       0                 0                -   \n",
       "\n",
       "   http_orig_mime_types http_resp_mime_types        weird_name  weird_addl  \\\n",
       "0                     -                    -  bad_TCP_checksum           -   \n",
       "1                     -                    -                 -           -   \n",
       "2                     -                    -  bad_TCP_checksum           -   \n",
       "3                     -                    -                 -           -   \n",
       "4                     -                    -  bad_UDP_checksum           -   \n",
       "\n",
       "   weird_notice label  \n",
       "0             F     0  \n",
       "1             -     0  \n",
       "2             F     0  \n",
       "3             -     0  \n",
       "4             F     0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/TON_IoT-Datasets/Train_Test_datasets/Train_Test_Network_dataset/Train_Test_Network.csv\")\n",
    "df.pop('type')\n",
    "df.pop('ts')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_indexs = [0, 1, 2, 3, 4, 5, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41]\n",
    "num_indexs = [6, 7, 8, 10, 11, 12, 13, 14, 33, 34]\n",
    "#bool_indexs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which cols are categorical\n",
    "cat_index_bool = [False] * 42\n",
    "for e in cat_indexs:\n",
    "    cat_index_bool[e] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Percentage malware\n",
    "# perc = len(df.loc[df['label']==1])/len(df)\n",
    "# print(perc)\n",
    "# \n",
    "# # Balance dataset\n",
    "# num_anom = len(df.loc[df['label']==1])\n",
    "# df_anom = df.loc[df['label']==1]\n",
    "# df_balance = df.loc[df['label']==0]\n",
    "# df_balance = df_balance.sample(num_anom, replace=False)\n",
    "# df_concated = pd.concat([df_balance, df_anom])\n",
    "# balanced_data = df_concated\n",
    "\n",
    "# df = balanced_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.sample(TRAIN_SIZE + TEST_SIZE, random_state=21)\n",
    "\n",
    "train_data = data.head(TRAIN_SIZE)\n",
    "train_labels = train_data.pop('label')\n",
    "test_data = data.tail(TEST_SIZE)\n",
    "test_labels = test_data.pop('label')\n",
    "\n",
    "labels = data.pop('label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#IID or NOIID? SPLIT DATA AMONG CLIENTS\n",
    "client_id_train = np.random.choice(range(NUM_CLIENTS), size=TRAIN_SIZE, replace=True)\n",
    "client_id_test = np.random.choice(range(NUM_CLIENTS), size=TEST_SIZE, replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine max_client_ds_size and min_client_ds_size\n",
    "max_client_ds_size = -1\n",
    "min_client_ds_size = len(train_data.loc[client_id_train == 0])\n",
    "for id in range(0,NUM_CLIENTS):\n",
    "    tmp_len = len(train_data.loc[client_id_train == id])\n",
    "    if(tmp_len > max_client_ds_size):\n",
    "        max_client_ds_size = tmp_len\n",
    "    if(tmp_len < min_client_ds_size):\n",
    "        min_client_ds_size = tmp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN: Create a dict where keys are client ids format for tff.simulation.datasets.TestClientData\n",
    "# Create distance matrix with each client data min_client_ds_size rows\n",
    "\n",
    "train_cl_dict = {}\n",
    "for id in range(0,NUM_CLIENTS):\n",
    "    tmp_train_df = pd.DataFrame()\n",
    "    \n",
    "    tmp_features = train_data.loc[client_id_train == id]\n",
    "    tmp_labels = train_labels.loc[client_id_train == id]\n",
    "\n",
    "    tmp_gower_mat = gd.gower_matrix_limit_cols(tmp_features,min_client_ds_size,cat_features=cat_index_bool)\n",
    "    \n",
    "    for i in range(0,min_client_ds_size):\n",
    "        tmp_train_df[str(i)] = tmp_gower_mat[:,i]\n",
    "    \n",
    "    tmp_train_df['label'] = tmp_labels.values\n",
    "\n",
    "    tmp_train_dict = {name: np.array(value) \n",
    "                         for name, value in tmp_train_df.items()}\n",
    "    \n",
    "    train_cl_dict[str(id)]=tmp_train_dict.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST SPLITED\n",
    "\n",
    "test_cl_dict = {}\n",
    "for id in range(0,NUM_CLIENTS):\n",
    "    tmp_test_df = pd.DataFrame()\n",
    "    \n",
    "    train_instances = train_data.loc[client_id_train == id]\n",
    "    test_instances = test_data.loc[client_id_test == id]\n",
    "\n",
    "    tmp_features = pd.concat([train_instances, test_instances])\n",
    "    \n",
    "    tmp_labels = test_labels.loc[client_id_test == id]\n",
    "\n",
    "    tmp_gower_mat = gd.gower_matrix_limit_cols(tmp_features,min_client_ds_size,cat_features=cat_index_bool)\n",
    "    \n",
    "    for i in range(0,min_client_ds_size):\n",
    "        tmp_test_df[str(i)] = tmp_gower_mat[len(train_instances):,i]\n",
    "    \n",
    "    tmp_test_df['label'] = tmp_labels.values\n",
    "\n",
    "    tmp_test_dict = {name: np.array(value) \n",
    "                         for name, value in tmp_test_df.items()}\n",
    "    test_cl_dict[str(id)]=tmp_test_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 06:47:57.171487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-27 06:47:57.171516: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-27 06:47:57.171535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debian): /proc/driver/nvidia/version does not exist\n",
      "2022-06-27 06:47:57.171756: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#CONVERT TO TFF DATASET\n",
    "#netw_ds = tf.data.Dataset.from_tensor_slices((netw_features_dict, netw_labels))\n",
    "#netw_ds = tf.data.Dataset.from_tensor_slices(netw_features_dict)\n",
    "train_fd_ds = tff.simulation.datasets.TestClientData(train_cl_dict)\n",
    "test_fd_ds = tff.simulation.datasets.TestClientData(test_cl_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FedAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(keras_model, test_dataset):\n",
    "  \"\"\"Evaluate the acurracy of a keras model on a test dataset.\"\"\"\n",
    "  #metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "  metric = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "  for batch in test_dataset:\n",
    "    predictions = keras_model(batch['x'])\n",
    "    metric.update_state(y_true=batch['y'], y_pred=predictions)\n",
    "  return metric.result()\n",
    "\n",
    "def get_custom_dataset():\n",
    "  def element_fn(element):\n",
    "    tmp_features = []\n",
    "    for i in range(0,min_client_ds_size):\n",
    "      tmp_features.append(element[str(i)])\n",
    "    features = tf.convert_to_tensor(tmp_features, dtype=tf.float32)\n",
    "    \n",
    "    return collections.OrderedDict(\n",
    "      # tf.expand_dims? ADD MORE COLUMNS\n",
    "        x=features, y=element['label'])\n",
    "\n",
    "  def preprocess_train_dataset(dataset):\n",
    "    # Use buffer_size same as the maximum client dataset size,\n",
    "    return dataset.map(element_fn).shuffle(buffer_size=max_client_ds_size).repeat(\n",
    "        count=CLIENT_EPOCHS_PER_ROUND).batch(\n",
    "            BATCH_SIZE, drop_remainder=False)\n",
    "   \n",
    "  \n",
    "  def preprocess_test_dataset(dataset):\n",
    "    return dataset.map(element_fn).batch(\n",
    "        TEST_BATCH_SIZE, drop_remainder=False)\n",
    "  \n",
    "  netw_train = train_fd_ds.preprocess(preprocess_train_dataset)\n",
    "  \n",
    "  netw_test = preprocess_test_dataset(\n",
    "    test_fd_ds.create_tf_dataset_from_all_clients())\n",
    "  \n",
    "  return netw_train, netw_test\n",
    "\n",
    "\n",
    "def create_fedavg_model(only_digits=True):\n",
    "  \"\"\"The CNN model used in https://arxiv.org/abs/1602.05629.\n",
    "\n",
    "  Args:\n",
    "    only_digits: If True, uses a final layer with 10 outputs, for use with the\n",
    "      digits only EMNIST dataset. If False, uses 62 outputs for the larger\n",
    "      dataset.\n",
    "\n",
    "  Returns:\n",
    "    An uncompiled `tf.keras.Model`.\n",
    "  \"\"\"\n",
    "  initializer = tf.keras.initializers.GlorotNormal(seed=5)\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(min_client_ds_size,)),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\", kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    #tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    #tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    #tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    #tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(2),\n",
    "    #tf.keras.layers.Dense(2, activation=\"relu\"),\n",
    "    #tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    #tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    #tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    tf.keras.layers.Softmax()\n",
    "    ])\n",
    "\n",
    "\n",
    "def server_optimizer_fn():\n",
    "  return tf.keras.optimizers.Adam(learning_rate=SERVER_LEARNING_RATE)\n",
    "\n",
    "\n",
    "def client_optimizer_fn():\n",
    "  return tf.keras.optimizers.Adam(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.63004893), ('loss', 0.6792215), ('num_examples', 3268), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6755240\n",
      "Round 1\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.66708153), ('loss', 0.6629439), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6619678\n",
      "Round 2\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65024036), ('loss', 0.65385556), ('num_examples', 3328), ('num_batches', 54)])\n",
      "\tValidation loss:  0.6512167\n",
      "Round 3\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.66219515), ('loss', 0.6423678), ('num_examples', 3280), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6425799\n",
      "Round 4\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6537742), ('loss', 0.63597864), ('num_examples', 3206), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6354595\n",
      "Round 5\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64671814), ('loss', 0.6328936), ('num_examples', 3108), ('num_batches', 50)])\n",
      "\tValidation loss:  0.6296306\n",
      "Round 6\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.67526746), ('loss', 0.61694884), ('num_examples', 3178), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6250431\n",
      "Round 7\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6470948), ('loss', 0.626039), ('num_examples', 3270), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6220226\n",
      "Round 8\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6507837), ('loss', 0.6203454), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6207480\n",
      "Round 9\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6470948), ('loss', 0.6231591), ('num_examples', 3270), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6208655\n",
      "Round 10\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64007306), ('loss', 0.63478136), ('num_examples', 3284), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6216763\n",
      "Round 11\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6607471), ('loss', 0.6207595), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6227813\n",
      "Round 12\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65954775), ('loss', 0.62509936), ('num_examples', 3184), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6234763\n",
      "Round 13\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6490683), ('loss', 0.638044), ('num_examples', 3220), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6231806\n",
      "Round 14\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6752609), ('loss', 0.6116962), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6223142\n",
      "Round 15\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6789574), ('loss', 0.6020294), ('num_examples', 3146), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6210783\n",
      "Round 16\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6629561), ('loss', 0.6191064), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6194258\n",
      "Round 17\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6672862), ('loss', 0.60957134), ('num_examples', 3228), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6176610\n",
      "Round 18\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65468943), ('loss', 0.6201171), ('num_examples', 3284), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6159195\n",
      "Round 19\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65876484), ('loss', 0.61450225), ('num_examples', 3206), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6145177\n",
      "Round 20\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65876776), ('loss', 0.61547315), ('num_examples', 3376), ('num_batches', 55)])\n",
      "\tValidation loss:  0.6134693\n",
      "Round 21\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.66361976), ('loss', 0.61058605), ('num_examples', 3282), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6127698\n",
      "Round 22\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6548619), ('loss', 0.62017435), ('num_examples', 3332), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6120868\n",
      "Round 23\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65559655), ('loss', 0.6106604), ('num_examples', 3252), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6112574\n",
      "Round 24\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6419753), ('loss', 0.62098545), ('num_examples', 3240), ('num_batches', 52)])\n",
      "\tValidation loss:  0.6102571\n",
      "Round 25\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6432602), ('loss', 0.62280273), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6092227\n",
      "Round 26\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64585835), ('loss', 0.61910737), ('num_examples', 3332), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6081613\n",
      "Round 27\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6328358), ('loss', 0.6154547), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.6070072\n",
      "Round 28\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6507177), ('loss', 0.6070596), ('num_examples', 3344), ('num_batches', 54)])\n",
      "\tValidation loss:  0.6056934\n",
      "Round 29\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6586103), ('loss', 0.6058415), ('num_examples', 3310), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6044799\n",
      "Round 30\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.63944346), ('loss', 0.6124778), ('num_examples', 3306), ('num_batches', 53)])\n",
      "\tValidation loss:  0.6034040\n",
      "Round 31\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6702668), ('loss', 0.60306704), ('num_examples', 3148), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6022247\n",
      "Round 32\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65413535), ('loss', 0.60972077), ('num_examples', 3192), ('num_batches', 51)])\n",
      "\tValidation loss:  0.6010689\n",
      "Round 33\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6754601), ('loss', 0.5957942), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5999369\n",
      "Round 34\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6523096), ('loss', 0.6019407), ('num_examples', 3204), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5987877\n",
      "Round 35\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6357494), ('loss', 0.60612875), ('num_examples', 3256), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5973722\n",
      "Round 36\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6542333), ('loss', 0.6016158), ('num_examples', 3378), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5957701\n",
      "Round 37\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6456456), ('loss', 0.59671736), ('num_examples', 3330), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5941994\n",
      "Round 38\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6523096), ('loss', 0.5934697), ('num_examples', 3204), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5927223\n",
      "Round 39\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6587708), ('loss', 0.5979271), ('num_examples', 3124), ('num_batches', 50)])\n",
      "\tValidation loss:  0.5914024\n",
      "Round 40\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.66092306), ('loss', 0.5842846), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5899614\n",
      "Round 41\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6622889), ('loss', 0.5970743), ('num_examples', 3198), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5885273\n",
      "Round 42\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6789574), ('loss', 0.57754976), ('num_examples', 3146), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5869243\n",
      "Round 43\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64930993), ('loss', 0.5858225), ('num_examples', 3188), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5854560\n",
      "Round 44\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6460542), ('loss', 0.5903445), ('num_examples', 3396), ('num_batches', 55)])\n",
      "\tValidation loss:  0.5840383\n",
      "Round 45\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6444579), ('loss', 0.57917684), ('num_examples', 3302), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5826831\n",
      "Round 46\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6542333), ('loss', 0.58724296), ('num_examples', 3378), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5812925\n",
      "Round 47\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65419436), ('loss', 0.5862668), ('num_examples', 3314), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5799403\n",
      "Round 48\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.66896987), ('loss', 0.5822813), ('num_examples', 3184), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5784766\n",
      "Round 49\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.67047507), ('loss', 0.5774563), ('num_examples', 3326), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5769838\n",
      "Round 50\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6754601), ('loss', 0.5705625), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5754956\n",
      "Round 51\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6553428), ('loss', 0.5851772), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5738789\n",
      "Round 52\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6686009), ('loss', 0.5775621), ('num_examples', 3102), ('num_batches', 50)])\n",
      "\tValidation loss:  0.5722968\n",
      "Round 53\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6668762), ('loss', 0.55822945), ('num_examples', 3182), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5707535\n",
      "Round 54\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6486898), ('loss', 0.56871027), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5691361\n",
      "Round 55\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.66840494), ('loss', 0.5638571), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5675041\n",
      "Round 56\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.666065), ('loss', 0.5661638), ('num_examples', 3324), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5658292\n",
      "Round 57\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6832718), ('loss', 0.5619107), ('num_examples', 3252), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5642440\n",
      "Round 58\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.66477615), ('loss', 0.5628798), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5627460\n",
      "Round 59\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6978462), ('loss', 0.54559845), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5614089\n",
      "Round 60\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.66219515), ('loss', 0.56815016), ('num_examples', 3280), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5598397\n",
      "Round 61\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.666877), ('loss', 0.5583066), ('num_examples', 3170), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5582401\n",
      "Round 62\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6553428), ('loss', 0.5672422), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5564712\n",
      "Round 63\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7538652), ('loss', 0.5412879), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5549092\n",
      "Round 64\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7032622), ('loss', 0.5488564), ('num_examples', 3188), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5534067\n",
      "Round 65\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6676737), ('loss', 0.55806494), ('num_examples', 3310), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5517818\n",
      "Round 66\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.67533255), ('loss', 0.5535711), ('num_examples', 3308), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5500211\n",
      "Round 67\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.67350155), ('loss', 0.5648777), ('num_examples', 3170), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5485386\n",
      "Round 68\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6570352), ('loss', 0.5736255), ('num_examples', 3184), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5475339\n",
      "Round 69\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6800373), ('loss', 0.5551151), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5466220\n",
      "Round 70\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.74542123), ('loss', 0.54140025), ('num_examples', 3276), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5447236\n",
      "Round 71\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7039634), ('loss', 0.5446572), ('num_examples', 3280), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5426925\n",
      "Round 72\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.73081684), ('loss', 0.5288933), ('num_examples', 3232), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5399235\n",
      "Round 73\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7232645), ('loss', 0.53522074), ('num_examples', 3198), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5368720\n",
      "Round 74\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.683733), ('loss', 0.5487515), ('num_examples', 3086), ('num_batches', 50)])\n",
      "\tValidation loss:  0.5345455\n",
      "Round 75\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7446474), ('loss', 0.5498068), ('num_examples', 3176), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5325219\n",
      "Round 76\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7517241), ('loss', 0.5369294), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5305135\n",
      "Round 77\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7746345), ('loss', 0.5386708), ('num_examples', 3146), ('num_batches', 50)])\n",
      "\tValidation loss:  0.5285330\n",
      "Round 78\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.78113556), ('loss', 0.5218927), ('num_examples', 3276), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5265383\n",
      "Round 79\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7997528), ('loss', 0.5203628), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5245253\n",
      "Round 80\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7953416), ('loss', 0.5174283), ('num_examples', 3220), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5224123\n",
      "Round 81\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.82560295), ('loss', 0.501302), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5204208\n",
      "Round 82\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7858942), ('loss', 0.5321438), ('num_examples', 3176), ('num_batches', 51)])\n",
      "\tValidation loss:  0.5185263\n",
      "Round 83\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.78038585), ('loss', 0.5366931), ('num_examples', 3110), ('num_batches', 50)])\n",
      "\tValidation loss:  0.5165376\n",
      "Round 84\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.78174603), ('loss', 0.5028065), ('num_examples', 3276), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5143916\n",
      "Round 85\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.80650157), ('loss', 0.48558995), ('num_examples', 3230), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5120234\n",
      "Round 86\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.77695054), ('loss', 0.5280807), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5095970\n",
      "Round 87\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.78716415), ('loss', 0.52920103), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5076954\n",
      "Round 88\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7682559), ('loss', 0.544826), ('num_examples', 3314), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5075670\n",
      "Round 89\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.83050334), ('loss', 0.49445486), ('num_examples', 3298), ('num_batches', 53)])\n",
      "\tValidation loss:  0.5073233\n",
      "Round 90\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8244544), ('loss', 0.4896831), ('num_examples', 3116), ('num_batches', 50)])\n",
      "\tValidation loss:  0.5072682\n",
      "Round 91\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.76646155), ('loss', 0.51492524), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.5067641\n",
      "Round 92\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.77439386), ('loss', 0.5204146), ('num_examples', 3382), ('num_batches', 54)])\n",
      "\tValidation loss:  0.5049925\n",
      "Round 93\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8161249), ('loss', 0.4823611), ('num_examples', 3138), ('num_batches', 50)])\n",
      "\tValidation loss:  0.4986526\n",
      "Round 94\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.82598835), ('loss', 0.49669296), ('num_examples', 3086), ('num_batches', 50)])\n",
      "\tValidation loss:  0.4924027\n",
      "Round 95\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8190447), ('loss', 0.49547625), ('num_examples', 3266), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4870604\n",
      "Round 96\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.82173914), ('loss', 0.49065253), ('num_examples', 3220), ('num_batches', 52)])\n",
      "\tValidation loss:  0.4837828\n",
      "Round 97\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.84903306), ('loss', 0.4550014), ('num_examples', 3206), ('num_batches', 51)])\n",
      "\tValidation loss:  0.4815761\n",
      "Round 98\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8261539), ('loss', 0.4606449), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.4798976\n",
      "Round 99\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8354819), ('loss', 0.46894574), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.4786022\n",
      "Round 100\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.81894934), ('loss', 0.4870803), ('num_examples', 3198), ('num_batches', 51)])\n",
      "\tValidation loss:  0.4752424\n",
      "Round 101\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8213222), ('loss', 0.4846287), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.4718422\n",
      "Round 102\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.84576803), ('loss', 0.45047978), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.4696131\n",
      "Round 103\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.83302695), ('loss', 0.45676476), ('num_examples', 3264), ('num_batches', 52)])\n",
      "\tValidation loss:  0.4671120\n",
      "Round 104\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8265558), ('loss', 0.46556324), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4645878\n",
      "Round 105\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7885886), ('loss', 0.4729745), ('num_examples', 3330), ('num_batches', 54)])\n",
      "\tValidation loss:  0.4612518\n",
      "Round 106\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8397474), ('loss', 0.4420725), ('num_examples', 3326), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4581593\n",
      "Round 107\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8216266), ('loss', 0.45385125), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4550234\n",
      "Round 108\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8106884), ('loss', 0.45420632), ('num_examples', 3312), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4520043\n",
      "Round 109\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8317699), ('loss', 0.4459044), ('num_examples', 3198), ('num_batches', 51)])\n",
      "\tValidation loss:  0.4487714\n",
      "Round 110\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.80790275), ('loss', 0.44156128), ('num_examples', 3290), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4458206\n",
      "Round 111\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8333333), ('loss', 0.4461908), ('num_examples', 3108), ('num_batches', 50)])\n",
      "\tValidation loss:  0.4427558\n",
      "Round 112\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.82895523), ('loss', 0.4474955), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.4396347\n",
      "Round 113\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8343929), ('loss', 0.39977813), ('num_examples', 3146), ('num_batches', 51)])\n",
      "\tValidation loss:  0.4366724\n",
      "Round 114\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8217287), ('loss', 0.43548748), ('num_examples', 3332), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4334601\n",
      "Round 115\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.81857854), ('loss', 0.40246096), ('num_examples', 3208), ('num_batches', 52)])\n",
      "\tValidation loss:  0.4307775\n",
      "Round 116\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8302779), ('loss', 0.4285323), ('num_examples', 3382), ('num_batches', 54)])\n",
      "\tValidation loss:  0.4296301\n",
      "Round 117\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.82925373), ('loss', 0.43506953), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.4274899\n",
      "Round 118\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8241791), ('loss', 0.42993084), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.4223530\n",
      "Round 119\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.81917554), ('loss', 0.43576577), ('num_examples', 3202), ('num_batches', 52)])\n",
      "\tValidation loss:  0.4186776\n",
      "Round 120\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.81288344), ('loss', 0.40958637), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4148026\n",
      "Round 121\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.83354074), ('loss', 0.38902533), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.4115046\n",
      "Round 122\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8148599), ('loss', 0.4215421), ('num_examples', 3284), ('num_batches', 53)])\n",
      "\tValidation loss:  0.4079122\n",
      "Round 123\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.83587784), ('loss', 0.41693103), ('num_examples', 3144), ('num_batches', 50)])\n",
      "\tValidation loss:  0.4038322\n",
      "Round 124\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.82685405), ('loss', 0.38688543), ('num_examples', 3344), ('num_batches', 54)])\n",
      "\tValidation loss:  0.4004356\n",
      "Round 125\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8368076), ('loss', 0.37399435), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.3971623\n",
      "Round 126\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8305539), ('loss', 0.397449), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.3940939\n",
      "Round 127\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8119076), ('loss', 0.4071097), ('num_examples', 3376), ('num_batches', 55)])\n",
      "\tValidation loss:  0.3912892\n",
      "Round 128\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8238566), ('loss', 0.40004992), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3877779\n",
      "Round 129\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.82546586), ('loss', 0.38656688), ('num_examples', 3220), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3853412\n",
      "Round 130\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.85768026), ('loss', 0.36390504), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.3853177\n",
      "Round 131\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8291536), ('loss', 0.39361492), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.3883021\n",
      "Round 132\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8303681), ('loss', 0.36802027), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3878646\n",
      "Round 133\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.84485924), ('loss', 0.36858472), ('num_examples', 3268), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3857463\n",
      "Round 134\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8288201), ('loss', 0.3686073), ('num_examples', 3102), ('num_batches', 50)])\n",
      "\tValidation loss:  0.3771079\n",
      "Round 135\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.82828283), ('loss', 0.3461134), ('num_examples', 3168), ('num_batches', 51)])\n",
      "\tValidation loss:  0.3683143\n",
      "Round 136\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8361529), ('loss', 0.3725787), ('num_examples', 3192), ('num_batches', 51)])\n",
      "\tValidation loss:  0.3654360\n",
      "Round 137\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.819609), ('loss', 0.37014022), ('num_examples', 3376), ('num_batches', 55)])\n",
      "\tValidation loss:  0.3683853\n",
      "Round 138\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8117117), ('loss', 0.36473468), ('num_examples', 3330), ('num_batches', 54)])\n",
      "\tValidation loss:  0.3695997\n",
      "Round 139\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.83598727), ('loss', 0.34926447), ('num_examples', 3140), ('num_batches', 50)])\n",
      "\tValidation loss:  0.3665180\n",
      "Round 140\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8547419), ('loss', 0.34955853), ('num_examples', 3332), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3533728\n",
      "Round 141\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8291299), ('loss', 0.36568055), ('num_examples', 3172), ('num_batches', 51)])\n",
      "\tValidation loss:  0.3457410\n",
      "Round 142\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.825716), ('loss', 0.35482076), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3430464\n",
      "Round 143\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.85563815), ('loss', 0.31501493), ('num_examples', 3228), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3418410\n",
      "Round 144\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.84178823), ('loss', 0.34044605), ('num_examples', 3154), ('num_batches', 51)])\n",
      "\tValidation loss:  0.3381134\n",
      "Round 145\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8401109), ('loss', 0.3489933), ('num_examples', 3246), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3330465\n",
      "Round 146\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8586103), ('loss', 0.30951896), ('num_examples', 3310), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3286014\n",
      "Round 147\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8213213), ('loss', 0.33730182), ('num_examples', 3330), ('num_batches', 54)])\n",
      "\tValidation loss:  0.3265892\n",
      "Round 148\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.84184915), ('loss', 0.3201983), ('num_examples', 3288), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3277936\n",
      "Round 149\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8510836), ('loss', 0.32794878), ('num_examples', 3230), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3228419\n",
      "Round 150\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.854829), ('loss', 0.3155533), ('num_examples', 3334), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3184807\n",
      "Round 151\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.839163), ('loss', 0.31641412), ('num_examples', 3202), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3149738\n",
      "Round 152\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8584672), ('loss', 0.3182146), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3122568\n",
      "Round 153\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.85984623), ('loss', 0.30197406), ('num_examples', 3382), ('num_batches', 54)])\n",
      "\tValidation loss:  0.3096807\n",
      "Round 154\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8400366), ('loss', 0.30831307), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3072247\n",
      "Round 155\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.85247463), ('loss', 0.28754687), ('num_examples', 3152), ('num_batches', 51)])\n",
      "\tValidation loss:  0.3049156\n",
      "Round 156\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8656307), ('loss', 0.3129844), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3033493\n",
      "Round 157\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.86904764), ('loss', 0.27874038), ('num_examples', 3276), ('num_batches', 53)])\n",
      "\tValidation loss:  0.3028024\n",
      "Round 158\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8695519), ('loss', 0.30655393), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3033381\n",
      "Round 159\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.87002486), ('loss', 0.30365682), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.3015431\n",
      "Round 160\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8703234), ('loss', 0.2793018), ('num_examples', 3154), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2978926\n",
      "Round 161\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8752351), ('loss', 0.28561082), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2932514\n",
      "Round 162\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.87322277), ('loss', 0.283267), ('num_examples', 3376), ('num_batches', 55)])\n",
      "\tValidation loss:  0.2882472\n",
      "Round 163\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8661839), ('loss', 0.27944672), ('num_examples', 3176), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2843606\n",
      "Round 164\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.88399), ('loss', 0.26138136), ('num_examples', 3198), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2819006\n",
      "Round 165\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8729913), ('loss', 0.28669804), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2800010\n",
      "Round 166\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8767696), ('loss', 0.2869076), ('num_examples', 3108), ('num_batches', 50)])\n",
      "\tValidation loss:  0.2772419\n",
      "Round 167\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8789634), ('loss', 0.26870427), ('num_examples', 3280), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2752406\n",
      "Round 168\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8742982), ('loss', 0.27587053), ('num_examples', 3206), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2742941\n",
      "Round 169\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.88579303), ('loss', 0.25890365), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2740191\n",
      "Round 170\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.88461536), ('loss', 0.25828344), ('num_examples', 3380), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2712168\n",
      "Round 171\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8732919), ('loss', 0.27319688), ('num_examples', 3220), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2658835\n",
      "Round 172\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8821188), ('loss', 0.26600885), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2622265\n",
      "Round 173\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9052407), ('loss', 0.24419911), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2582023\n",
      "Round 174\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8902439), ('loss', 0.23883002), ('num_examples', 3280), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2566251\n",
      "Round 175\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.88695127), ('loss', 0.24780025), ('num_examples', 3326), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2554676\n",
      "Round 176\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.87589496), ('loss', 0.2672767), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2537321\n",
      "Round 177\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8749254), ('loss', 0.2607505), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2514766\n",
      "Round 178\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.88654196), ('loss', 0.25377795), ('num_examples', 3314), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2496221\n",
      "Round 179\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8968059), ('loss', 0.23511834), ('num_examples', 3256), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2479076\n",
      "Round 180\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.89603364), ('loss', 0.2432083), ('num_examples', 3328), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2464844\n",
      "Round 181\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.89241296), ('loss', 0.24095999), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2444251\n",
      "Round 182\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.90385795), ('loss', 0.2272119), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2420067\n",
      "Round 183\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.89001226), ('loss', 0.2506791), ('num_examples', 3264), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2409294\n",
      "Round 184\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8976015), ('loss', 0.23463678), ('num_examples', 3252), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2393339\n",
      "Round 185\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8874688), ('loss', 0.23779282), ('num_examples', 3208), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2363887\n",
      "Round 186\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9113497), ('loss', 0.22379664), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2339465\n",
      "Round 187\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8763407), ('loss', 0.24824253), ('num_examples', 3170), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2367288\n",
      "Round 188\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8811881), ('loss', 0.24246268), ('num_examples', 3232), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2376651\n",
      "Round 189\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.897673), ('loss', 0.2387161), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2343545\n",
      "Round 190\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8981829), ('loss', 0.23959653), ('num_examples', 3192), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2274065\n",
      "Round 191\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.89699435), ('loss', 0.23994614), ('num_examples', 3194), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2245779\n",
      "Round 192\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9124311), ('loss', 0.2160369), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2244955\n",
      "Round 193\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9102252), ('loss', 0.20544551), ('num_examples', 3286), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2256962\n",
      "Round 194\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.90655047), ('loss', 0.21480642), ('num_examples', 3328), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2245137\n",
      "Round 195\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9148999), ('loss', 0.21009853), ('num_examples', 3396), ('num_batches', 55)])\n",
      "\tValidation loss:  0.2210232\n",
      "Round 196\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9077469), ('loss', 0.21631765), ('num_examples', 3382), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2179673\n",
      "Round 197\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9188558), ('loss', 0.1993433), ('num_examples', 3426), ('num_batches', 55)])\n",
      "\tValidation loss:  0.2158224\n",
      "Round 198\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9160305), ('loss', 0.19605854), ('num_examples', 3406), ('num_batches', 55)])\n",
      "\tValidation loss:  0.2217955\n",
      "Round 199\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9124311), ('loss', 0.20487098), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2234811\n",
      "Round 200\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9058539), ('loss', 0.2079185), ('num_examples', 3314), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2186088\n",
      "Round 201\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92539966), ('loss', 0.18808971), ('num_examples', 3378), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2153248\n",
      "Round 202\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92055213), ('loss', 0.20345202), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2149187\n",
      "Round 203\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92265034), ('loss', 0.19256216), ('num_examples', 3426), ('num_batches', 55)])\n",
      "\tValidation loss:  0.2129900\n",
      "Round 204\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.91360945), ('loss', 0.19928415), ('num_examples', 3380), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2116682\n",
      "Round 205\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9332326), ('loss', 0.1794258), ('num_examples', 3310), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2112660\n",
      "Round 206\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.89285713), ('loss', 0.22671644), ('num_examples', 3164), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2104991\n",
      "Round 207\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.91159874), ('loss', 0.20218636), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2101047\n",
      "Round 208\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9146778), ('loss', 0.20493133), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2079712\n",
      "Round 209\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92392635), ('loss', 0.19176175), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2065384\n",
      "Round 210\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9139093), ('loss', 0.1912654), ('num_examples', 3264), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2064157\n",
      "Round 211\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9177489), ('loss', 0.19779935), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2050573\n",
      "Round 212\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92507464), ('loss', 0.18825257), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2034433\n",
      "Round 213\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.91797614), ('loss', 0.19565086), ('num_examples', 3182), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2019375\n",
      "Round 214\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8963682), ('loss', 0.22035624), ('num_examples', 3194), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2008262\n",
      "Round 215\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9224351), ('loss', 0.18615153), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1999891\n",
      "Round 216\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9089196), ('loss', 0.20969546), ('num_examples', 3184), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1987700\n",
      "Round 217\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.925015), ('loss', 0.18166849), ('num_examples', 3334), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1980186\n",
      "Round 218\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.91661483), ('loss', 0.20705774), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1970704\n",
      "Round 219\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92032474), ('loss', 0.18019277), ('num_examples', 3326), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1960526\n",
      "Round 220\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.89840764), ('loss', 0.22146423), ('num_examples', 3140), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1960624\n",
      "Round 221\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9172371), ('loss', 0.18982945), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1947702\n",
      "Round 222\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.90945864), ('loss', 0.20152992), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1938140\n",
      "Round 223\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.91720873), ('loss', 0.18481737), ('num_examples', 3382), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1934995\n",
      "Round 224\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9308968), ('loss', 0.17633747), ('num_examples', 3256), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1933182\n",
      "Round 225\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92584616), ('loss', 0.17708148), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1924788\n",
      "Round 226\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9147968), ('loss', 0.18989599), ('num_examples', 3298), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1926347\n",
      "Round 227\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9245169), ('loss', 0.17691584), ('num_examples', 3312), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1924432\n",
      "Round 228\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93446153), ('loss', 0.16152932), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1920073\n",
      "Round 229\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.91542286), ('loss', 0.18598384), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1915831\n",
      "Round 230\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9283527), ('loss', 0.17456803), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1930655\n",
      "Round 231\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9189772), ('loss', 0.18917459), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1909647\n",
      "Round 232\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9258207), ('loss', 0.1767819), ('num_examples', 3168), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1886744\n",
      "Round 233\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.91178346), ('loss', 0.20251533), ('num_examples', 3140), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1872774\n",
      "Round 234\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9317489), ('loss', 0.17699878), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1856958\n",
      "Round 235\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.91998774), ('loss', 0.18139033), ('num_examples', 3262), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1863042\n",
      "Round 236\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92762744), ('loss', 0.17742082), ('num_examples', 3178), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1944921\n",
      "Round 237\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9184682), ('loss', 0.19395083), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1980705\n",
      "Round 238\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9236499), ('loss', 0.19140323), ('num_examples', 3222), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1874325\n",
      "Round 239\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.935061), ('loss', 0.15538462), ('num_examples', 3280), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1809992\n",
      "Round 240\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9310651), ('loss', 0.15911186), ('num_examples', 3380), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1806426\n",
      "Round 241\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9328404), ('loss', 0.17432986), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1814721\n",
      "Round 242\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94397336), ('loss', 0.1650042), ('num_examples', 3302), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1794198\n",
      "Round 243\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9201238), ('loss', 0.1768005), ('num_examples', 3230), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1781311\n",
      "Round 244\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94), ('loss', 0.16740832), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1805665\n",
      "Round 245\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9402803), ('loss', 0.16043329), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1842212\n",
      "Round 246\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92496926), ('loss', 0.18503836), ('num_examples', 3252), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1799699\n",
      "Round 247\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9253267), ('loss', 0.18052132), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1770158\n",
      "Round 248\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93815064), ('loss', 0.17022887), ('num_examples', 3266), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1770660\n",
      "Round 249\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92834693), ('loss', 0.17661983), ('num_examples', 3182), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1771802\n",
      "Round 250\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9303759), ('loss', 0.1651401), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1782295\n",
      "Round 251\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9420768), ('loss', 0.14574695), ('num_examples', 3332), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1810440\n",
      "Round 252\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93645585), ('loss', 0.17010194), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1792322\n",
      "Round 253\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9263126), ('loss', 0.17689161), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1773589\n",
      "Round 254\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9349315), ('loss', 0.16267063), ('num_examples', 3212), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1792414\n",
      "Round 255\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9322344), ('loss', 0.16320984), ('num_examples', 3276), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1799836\n",
      "Round 256\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92852795), ('loss', 0.16656645), ('num_examples', 3288), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1852902\n",
      "Round 257\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93675417), ('loss', 0.16643222), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1835785\n",
      "Round 258\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93374234), ('loss', 0.1645283), ('num_examples', 3260), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1774801\n",
      "Round 259\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93591297), ('loss', 0.15789688), ('num_examples', 3308), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1872886\n",
      "Round 260\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93555415), ('loss', 0.16336003), ('num_examples', 3212), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1964164\n",
      "Round 261\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9350571), ('loss', 0.15657172), ('num_examples', 3326), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1917761\n",
      "Round 262\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92575186), ('loss', 0.18310788), ('num_examples', 3192), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1778700\n",
      "Round 263\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93810093), ('loss', 0.16159002), ('num_examples', 3328), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1766357\n",
      "Round 264\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.92084944), ('loss', 0.1743772), ('num_examples', 3108), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1858243\n",
      "Round 265\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9477791), ('loss', 0.137302), ('num_examples', 3332), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2032384\n",
      "Round 266\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9301607), ('loss', 0.17220585), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1968208\n",
      "Round 267\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9312303), ('loss', 0.16554113), ('num_examples', 3170), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1783058\n",
      "Round 268\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9351168), ('loss', 0.1543852), ('num_examples', 3252), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1702102\n",
      "Round 269\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93896574), ('loss', 0.14831348), ('num_examples', 3326), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1720823\n",
      "Round 270\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9282132), ('loss', 0.16828965), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1795565\n",
      "Round 271\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9419036), ('loss', 0.1544554), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1866311\n",
      "Round 272\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9347962), ('loss', 0.15894917), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1800894\n",
      "Round 273\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9439629), ('loss', 0.14369978), ('num_examples', 3230), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1720591\n",
      "Round 274\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9521739), ('loss', 0.13944738), ('num_examples', 3220), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1671518\n",
      "Round 275\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93405926), ('loss', 0.1509685), ('num_examples', 3306), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1685141\n",
      "Round 276\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.931903), ('loss', 0.1637064), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1679113\n",
      "Round 277\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94182575), ('loss', 0.14822412), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1668590\n",
      "Round 278\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94056374), ('loss', 0.13800015), ('num_examples', 3264), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1657749\n",
      "Round 279\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94338423), ('loss', 0.14184652), ('num_examples', 3144), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1649399\n",
      "Round 280\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93523633), ('loss', 0.15808083), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1642381\n",
      "Round 281\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9362292), ('loss', 0.15523928), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1649955\n",
      "Round 282\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9476489), ('loss', 0.14021373), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1643688\n",
      "Round 283\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9334554), ('loss', 0.15857752), ('num_examples', 3276), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1710203\n",
      "Round 284\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93926996), ('loss', 0.14945933), ('num_examples', 3178), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1826180\n",
      "Round 285\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94246405), ('loss', 0.15116876), ('num_examples', 3198), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1853943\n",
      "Round 286\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93453103), ('loss', 0.16563092), ('num_examples', 3284), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1805079\n",
      "Round 287\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95851), ('loss', 0.13130073), ('num_examples', 3302), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1662742\n",
      "Round 288\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9442391), ('loss', 0.14219503), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1603031\n",
      "Round 289\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95485467), ('loss', 0.13302337), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1598670\n",
      "Round 290\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9363749), ('loss', 0.1555787), ('num_examples', 3222), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1607252\n",
      "Round 291\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9419615), ('loss', 0.15272294), ('num_examples', 3222), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1691137\n",
      "Round 292\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9378411), ('loss', 0.14864706), ('num_examples', 3298), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1664360\n",
      "Round 293\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94471896), ('loss', 0.14005421), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1649262\n",
      "Round 294\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9417622), ('loss', 0.14022326), ('num_examples', 3314), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1588858\n",
      "Round 295\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9400124), ('loss', 0.14809777), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1603690\n",
      "Round 296\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9408701), ('loss', 0.13718174), ('num_examples', 3264), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1752668\n",
      "Round 297\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95051295), ('loss', 0.13247646), ('num_examples', 3314), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1854333\n",
      "Round 298\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9358592), ('loss', 0.15124439), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1744201\n",
      "Round 299\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94294673), ('loss', 0.14079973), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1576165\n",
      "Round 300\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95075756), ('loss', 0.13637543), ('num_examples', 3168), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1686901\n",
      "Round 301\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94756097), ('loss', 0.1326754), ('num_examples', 3280), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1825306\n",
      "Round 302\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9411948), ('loss', 0.15199406), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1708096\n",
      "Round 303\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94711536), ('loss', 0.13528205), ('num_examples', 3328), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1580132\n",
      "Round 304\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9481688), ('loss', 0.13889182), ('num_examples', 3222), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1678201\n",
      "Round 305\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9360073), ('loss', 0.14467679), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1717326\n",
      "Round 306\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94669443), ('loss', 0.12796892), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1712006\n",
      "Round 307\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94808745), ('loss', 0.12890144), ('num_examples', 3294), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1684431\n",
      "Round 308\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93712395), ('loss', 0.15028778), ('num_examples', 3324), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1701695\n",
      "Round 309\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93526083), ('loss', 0.14456475), ('num_examples', 3182), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1751566\n",
      "Round 310\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94330555), ('loss', 0.13740005), ('num_examples', 3122), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1747097\n",
      "Round 311\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95222354), ('loss', 0.12266474), ('num_examples', 3328), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1718379\n",
      "Round 312\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95376605), ('loss', 0.13320391), ('num_examples', 3266), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1667396\n",
      "Round 313\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9458619), ('loss', 0.13369496), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1633246\n",
      "Round 314\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.946418), ('loss', 0.12830307), ('num_examples', 3378), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1581486\n",
      "Round 315\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93610936), ('loss', 0.14923012), ('num_examples', 3146), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1641978\n",
      "Round 316\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94210523), ('loss', 0.13863003), ('num_examples', 3230), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1709690\n",
      "Round 317\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.93642724), ('loss', 0.15195541), ('num_examples', 3146), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1609569\n",
      "Round 318\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94758785), ('loss', 0.1276362), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1554951\n",
      "Round 319\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9467343), ('loss', 0.12898634), ('num_examples', 3154), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1539634\n",
      "Round 320\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94779724), ('loss', 0.12644848), ('num_examples', 3314), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1552671\n",
      "Round 321\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95305026), ('loss', 0.11818963), ('num_examples', 3344), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1580071\n",
      "Round 322\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9456722), ('loss', 0.13312732), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1561440\n",
      "Round 323\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9394885), ('loss', 0.13956876), ('num_examples', 3206), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1522784\n",
      "Round 324\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94840074), ('loss', 0.12436925), ('num_examples', 3314), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1538320\n",
      "Round 325\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9486216), ('loss', 0.13546664), ('num_examples', 3192), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1720245\n",
      "Round 326\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9472882), ('loss', 0.13287438), ('num_examples', 3282), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1969633\n",
      "Round 327\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94626313), ('loss', 0.12673718), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1943307\n",
      "Round 328\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9494275), ('loss', 0.12732446), ('num_examples', 3144), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1646276\n",
      "Round 329\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94924474), ('loss', 0.12869135), ('num_examples', 3310), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1507725\n",
      "Round 330\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9523077), ('loss', 0.11978984), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1744468\n",
      "Round 331\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94869405), ('loss', 0.13017695), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2005948\n",
      "Round 332\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9536083), ('loss', 0.115765415), ('num_examples', 3298), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2123079\n",
      "Round 333\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9483384), ('loss', 0.120186225), ('num_examples', 3310), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1817126\n",
      "Round 334\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94769233), ('loss', 0.115900576), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1506836\n",
      "Round 335\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9559432), ('loss', 0.11888519), ('num_examples', 3382), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1784240\n",
      "Round 336\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95405406), ('loss', 0.11200389), ('num_examples', 3330), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2325464\n",
      "Round 337\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9567337), ('loss', 0.122066274), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2264110\n",
      "Round 338\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9481688), ('loss', 0.12525268), ('num_examples', 3222), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1860124\n",
      "Round 339\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9470117), ('loss', 0.11867747), ('num_examples', 3246), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1611317\n",
      "Round 340\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94962686), ('loss', 0.13000982), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1516498\n",
      "Round 341\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94715446), ('loss', 0.121836446), ('num_examples', 3198), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1732948\n",
      "Round 342\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95889604), ('loss', 0.105602615), ('num_examples', 3406), ('num_batches', 55)])\n",
      "\tValidation loss:  0.1919685\n",
      "Round 343\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95671266), ('loss', 0.115006834), ('num_examples', 3188), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1820463\n",
      "Round 344\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9568323), ('loss', 0.111275874), ('num_examples', 3220), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1527906\n",
      "Round 345\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9559094), ('loss', 0.11241297), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1572684\n",
      "Round 346\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9418309), ('loss', 0.13502164), ('num_examples', 3146), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1601931\n",
      "Round 347\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95179236), ('loss', 0.12656035), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1555362\n",
      "Round 348\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9560073), ('loss', 0.1112827), ('num_examples', 3296), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1490315\n",
      "Round 349\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9468085), ('loss', 0.12864663), ('num_examples', 3102), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1497697\n",
      "Round 350\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9517704), ('loss', 0.12008026), ('num_examples', 3276), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1662897\n",
      "Round 351\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9568323), ('loss', 0.109286), ('num_examples', 3220), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1634470\n",
      "Round 352\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96033657), ('loss', 0.10584445), ('num_examples', 3328), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1558250\n",
      "Round 353\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9627329), ('loss', 0.10777687), ('num_examples', 3220), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1468309\n",
      "Round 354\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9560099), ('loss', 0.10854842), ('num_examples', 3228), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1507990\n",
      "Round 355\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9597975), ('loss', 0.10294447), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1492714\n",
      "Round 356\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9498433), ('loss', 0.11905802), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1494005\n",
      "Round 357\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95856017), ('loss', 0.10855433), ('num_examples', 3306), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1521081\n",
      "Round 358\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95992714), ('loss', 0.10517562), ('num_examples', 3294), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1520350\n",
      "Round 359\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9559006), ('loss', 0.10357576), ('num_examples', 3220), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1572177\n",
      "Round 360\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9558011), ('loss', 0.11563173), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1597577\n",
      "Round 361\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9577241), ('loss', 0.11110397), ('num_examples', 3146), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1588108\n",
      "Round 362\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9590062), ('loss', 0.104746334), ('num_examples', 3220), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1601198\n",
      "Round 363\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9539723), ('loss', 0.114420734), ('num_examples', 3172), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1601273\n",
      "Round 364\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94417477), ('loss', 0.13399978), ('num_examples', 3296), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1474575\n",
      "Round 365\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9606004), ('loss', 0.10477457), ('num_examples', 3198), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1539232\n",
      "Round 366\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9604247), ('loss', 0.10518281), ('num_examples', 3108), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1667800\n",
      "Round 367\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9582346), ('loss', 0.10567229), ('num_examples', 3376), ('num_batches', 55)])\n",
      "\tValidation loss:  0.1729660\n",
      "Round 368\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96716416), ('loss', 0.087664194), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1572814\n",
      "Round 369\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95224893), ('loss', 0.117585205), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1472588\n",
      "Round 370\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9651019), ('loss', 0.09517991), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1440908\n",
      "Round 371\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94803196), ('loss', 0.12637776), ('num_examples', 3252), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1533725\n",
      "Round 372\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9567705), ('loss', 0.119269185), ('num_examples', 3146), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1744704\n",
      "Round 373\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9549969), ('loss', 0.10907746), ('num_examples', 3222), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1984546\n",
      "Round 374\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95375544), ('loss', 0.107643925), ('num_examples', 3222), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2070239\n",
      "Round 375\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96215385), ('loss', 0.092477255), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1871547\n",
      "Round 376\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9609231), ('loss', 0.097749196), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1587000\n",
      "Round 377\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9558196), ('loss', 0.107758835), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1449379\n",
      "Round 378\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9539515), ('loss', 0.11128335), ('num_examples', 3214), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1622188\n",
      "Round 379\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95205045), ('loss', 0.112868525), ('num_examples', 3170), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1722340\n",
      "Round 380\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95462906), ('loss', 0.11393689), ('num_examples', 3262), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1811039\n",
      "Round 381\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95933014), ('loss', 0.10191347), ('num_examples', 3344), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1750833\n",
      "Round 382\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94850606), ('loss', 0.12540536), ('num_examples', 3146), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1473164\n",
      "Round 383\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9555891), ('loss', 0.1032829), ('num_examples', 3310), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1547814\n",
      "Round 384\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.967615), ('loss', 0.09282014), ('num_examples', 3304), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1808222\n",
      "Round 385\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96221817), ('loss', 0.09520381), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1897259\n",
      "Round 386\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9612825), ('loss', 0.10454485), ('num_examples', 3306), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1683362\n",
      "Round 387\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9692537), ('loss', 0.0890859), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1498587\n",
      "Round 388\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95069534), ('loss', 0.11459275), ('num_examples', 3164), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1473215\n",
      "Round 389\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9584383), ('loss', 0.10357566), ('num_examples', 3176), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1538062\n",
      "Round 390\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9599874), ('loss', 0.098248765), ('num_examples', 3174), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1594841\n",
      "Round 391\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9721542), ('loss', 0.0875983), ('num_examples', 3268), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1535989\n",
      "Round 392\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97046155), ('loss', 0.08134106), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1463271\n",
      "Round 393\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9660284), ('loss', 0.08893299), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1496587\n",
      "Round 394\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9604608), ('loss', 0.1063713), ('num_examples', 3212), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1720364\n",
      "Round 395\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9526515), ('loss', 0.11698157), ('num_examples', 3168), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1755544\n",
      "Round 396\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9660074), ('loss', 0.08663607), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1650113\n",
      "Round 397\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9608749), ('loss', 0.09800321), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1489841\n",
      "Round 398\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.960625), ('loss', 0.09230965), ('num_examples', 3200), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1455973\n",
      "Round 399\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9659158), ('loss', 0.08659619), ('num_examples', 3374), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1506852\n",
      "Round 400\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96363634), ('loss', 0.09093963), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1506514\n",
      "Round 401\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95280147), ('loss', 0.10608206), ('num_examples', 3284), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1450160\n",
      "Round 402\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9751479), ('loss', 0.07301346), ('num_examples', 3380), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1446747\n",
      "Round 403\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96666664), ('loss', 0.095001705), ('num_examples', 3270), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1599853\n",
      "Round 404\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96123075), ('loss', 0.10403583), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1562032\n",
      "Round 405\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95415384), ('loss', 0.11673563), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1421607\n",
      "Round 406\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9636143), ('loss', 0.10047009), ('num_examples', 3298), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1470141\n",
      "Round 407\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95770395), ('loss', 0.10533107), ('num_examples', 3310), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1875185\n",
      "Round 408\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96191347), ('loss', 0.092976235), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2017331\n",
      "Round 409\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.94915783), ('loss', 0.117016815), ('num_examples', 3206), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1838739\n",
      "Round 410\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96127635), ('loss', 0.10277783), ('num_examples', 3228), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1621284\n",
      "Round 411\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96330845), ('loss', 0.101612434), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1428917\n",
      "Round 412\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9653553), ('loss', 0.08704147), ('num_examples', 3406), ('num_batches', 55)])\n",
      "\tValidation loss:  0.1467860\n",
      "Round 413\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9567585), ('loss', 0.11397858), ('num_examples', 3122), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1675349\n",
      "Round 414\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96439534), ('loss', 0.091201305), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1960048\n",
      "Round 415\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9713433), ('loss', 0.07994697), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1787385\n",
      "Round 416\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9611318), ('loss', 0.09938275), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1503348\n",
      "Round 417\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9622758), ('loss', 0.09480315), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1449381\n",
      "Round 418\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9726148), ('loss', 0.08064976), ('num_examples', 3396), ('num_batches', 55)])\n",
      "\tValidation loss:  0.1896851\n",
      "Round 419\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9610942), ('loss', 0.10025464), ('num_examples', 3290), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2130712\n",
      "Round 420\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96179914), ('loss', 0.09481233), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1595170\n",
      "Round 421\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.967411), ('loss', 0.08437396), ('num_examples', 3314), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1597643\n",
      "Round 422\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9588385), ('loss', 0.092952155), ('num_examples', 3134), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2538442\n",
      "Round 423\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96314806), ('loss', 0.095256366), ('num_examples', 3202), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2694737\n",
      "Round 424\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9686391), ('loss', 0.07877116), ('num_examples', 3380), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2008436\n",
      "Round 425\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95789146), ('loss', 0.11019012), ('num_examples', 3206), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1501419\n",
      "Round 426\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9606154), ('loss', 0.09903832), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1926121\n",
      "Round 427\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95982695), ('loss', 0.09758886), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2643335\n",
      "Round 428\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9606909), ('loss', 0.10329828), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2279114\n",
      "Round 429\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95), ('loss', 0.117180265), ('num_examples', 3240), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1569345\n",
      "Round 430\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9522293), ('loss', 0.113484114), ('num_examples', 3140), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1582866\n",
      "Round 431\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97014016), ('loss', 0.086201824), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1894686\n",
      "Round 432\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.967838), ('loss', 0.08187286), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2168342\n",
      "Round 433\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9678639), ('loss', 0.08138876), ('num_examples', 3174), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1925914\n",
      "Round 434\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96217984), ('loss', 0.09687094), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1503242\n",
      "Round 435\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9736842), ('loss', 0.071380295), ('num_examples', 3382), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1341055\n",
      "Round 436\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95645267), ('loss', 0.111709684), ('num_examples', 3146), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1530245\n",
      "Round 437\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96558315), ('loss', 0.08810966), ('num_examples', 3138), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1904522\n",
      "Round 438\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96182966), ('loss', 0.0946537), ('num_examples', 3170), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1583376\n",
      "Round 439\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97071254), ('loss', 0.07639244), ('num_examples', 3312), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1355073\n",
      "Round 440\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9731465), ('loss', 0.064267635), ('num_examples', 3426), ('num_batches', 55)])\n",
      "\tValidation loss:  0.1844145\n",
      "Round 441\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9671924), ('loss', 0.08446032), ('num_examples', 3170), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2639019\n",
      "Round 442\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95435685), ('loss', 0.11876101), ('num_examples', 3374), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2490026\n",
      "Round 443\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9726708), ('loss', 0.07166997), ('num_examples', 3220), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1724775\n",
      "Round 444\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9676617), ('loss', 0.07504574), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1389726\n",
      "Round 445\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.969279), ('loss', 0.08929127), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1553157\n",
      "Round 446\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96795684), ('loss', 0.08479242), ('num_examples', 3152), ('num_batches', 51)])\n",
      "\tValidation loss:  0.2169631\n",
      "Round 447\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95735025), ('loss', 0.10188213), ('num_examples', 3306), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2093052\n",
      "Round 448\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9689441), ('loss', 0.07878936), ('num_examples', 3220), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1449443\n",
      "Round 449\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.966397), ('loss', 0.084432274), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1432001\n",
      "Round 450\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9648799), ('loss', 0.08926362), ('num_examples', 3246), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1683840\n",
      "Round 451\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9784024), ('loss', 0.067456886), ('num_examples', 3380), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1775769\n",
      "Round 452\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9622991), ('loss', 0.09668172), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1627134\n",
      "Round 453\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9726891), ('loss', 0.06842703), ('num_examples', 3332), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1469166\n",
      "Round 454\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9567004), ('loss', 0.1018259), ('num_examples', 3164), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1390436\n",
      "Round 455\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9699226), ('loss', 0.073386684), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1379370\n",
      "Round 456\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.964939), ('loss', 0.09669567), ('num_examples', 3280), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1416098\n",
      "Round 457\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97340757), ('loss', 0.07433048), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1601309\n",
      "Round 458\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9710641), ('loss', 0.07974392), ('num_examples', 3214), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1826537\n",
      "Round 459\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9667692), ('loss', 0.08521123), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2159617\n",
      "Round 460\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96039003), ('loss', 0.09572034), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1551701\n",
      "Round 461\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9680251), ('loss', 0.0831675), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1401195\n",
      "Round 462\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9720687), ('loss', 0.0776369), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2171934\n",
      "Round 463\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97225535), ('loss', 0.079538144), ('num_examples', 3352), ('num_batches', 54)])\n",
      "\tValidation loss:  0.2842149\n",
      "Round 464\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96123075), ('loss', 0.10831611), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2133745\n",
      "Round 465\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97476923), ('loss', 0.070937835), ('num_examples', 3250), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1533418\n",
      "Round 466\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.968652), ('loss', 0.08745999), ('num_examples', 3190), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1435222\n",
      "Round 467\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9609619), ('loss', 0.08720319), ('num_examples', 3202), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1700658\n",
      "Round 468\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9602922), ('loss', 0.0976951), ('num_examples', 3148), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1707653\n",
      "Round 469\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.981194), ('loss', 0.06172101), ('num_examples', 3350), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1512691\n",
      "Round 470\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9819462), ('loss', 0.05988235), ('num_examples', 3268), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1437206\n",
      "Round 471\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9633193), ('loss', 0.097920775), ('num_examples', 3326), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1525078\n",
      "Round 472\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9779722), ('loss', 0.06458776), ('num_examples', 3314), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1576498\n",
      "Round 473\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9681509), ('loss', 0.08558918), ('num_examples', 3234), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1477102\n",
      "Round 474\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9695734), ('loss', 0.08698491), ('num_examples', 3188), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1511684\n",
      "Round 475\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9737492), ('loss', 0.06765572), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1589314\n",
      "Round 476\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.95676005), ('loss', 0.09849171), ('num_examples', 3284), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1539709\n",
      "Round 477\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9768548), ('loss', 0.06400817), ('num_examples', 3154), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1464202\n",
      "Round 478\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96630645), ('loss', 0.07999294), ('num_examples', 3146), ('num_batches', 50)])\n",
      "\tValidation loss:  0.1779530\n",
      "Round 479\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9799259), ('loss', 0.059340477), ('num_examples', 3238), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2069691\n",
      "Round 480\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97442144), ('loss', 0.07186041), ('num_examples', 3284), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1889372\n",
      "Round 481\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9723067), ('loss', 0.06647566), ('num_examples', 3286), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1616946\n",
      "Round 482\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97620517), ('loss', 0.061870627), ('num_examples', 3236), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1438561\n",
      "Round 483\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9678398), ('loss', 0.07820206), ('num_examples', 3296), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1536614\n",
      "Round 484\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9588705), ('loss', 0.10358891), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2491531\n",
      "Round 485\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9687875), ('loss', 0.07723972), ('num_examples', 3332), ('num_batches', 53)])\n",
      "\tValidation loss:  0.2533977\n",
      "Round 486\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9662614), ('loss', 0.08500901), ('num_examples', 3290), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1650097\n",
      "Round 487\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97534996), ('loss', 0.062243313), ('num_examples', 3286), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1548348\n",
      "Round 488\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9729478), ('loss', 0.082307085), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2351080\n",
      "Round 489\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9606671), ('loss', 0.09812436), ('num_examples', 3178), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2312051\n",
      "Round 490\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9687314), ('loss', 0.08530926), ('num_examples', 3358), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1659375\n",
      "Round 491\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96662587), ('loss', 0.09116083), ('num_examples', 3266), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1411914\n",
      "Round 492\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96585363), ('loss', 0.08196399), ('num_examples', 3280), ('num_batches', 52)])\n",
      "\tValidation loss:  0.1721516\n",
      "Round 493\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9632495), ('loss', 0.088668354), ('num_examples', 3102), ('num_batches', 50)])\n",
      "\tValidation loss:  0.2411686\n",
      "Round 494\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9574005), ('loss', 0.11567434), ('num_examples', 3216), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2399394\n",
      "Round 495\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96777165), ('loss', 0.07896685), ('num_examples', 3258), ('num_batches', 52)])\n",
      "\tValidation loss:  0.2017168\n",
      "Round 496\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.96319795), ('loss', 0.08709426), ('num_examples', 3152), ('num_batches', 51)])\n",
      "\tValidation loss:  0.1533882\n",
      "Round 497\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97202164), ('loss', 0.07345564), ('num_examples', 3324), ('num_batches', 54)])\n",
      "\tValidation loss:  0.1378955\n",
      "Round 498\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.97827363), ('loss', 0.05828383), ('num_examples', 3406), ('num_batches', 55)])\n",
      "\tValidation loss:  0.1462578\n",
      "Round 499\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.9811091), ('loss', 0.051386844), ('num_examples', 3282), ('num_batches', 53)])\n",
      "\tValidation loss:  0.1854749\n"
     ]
    }
   ],
   "source": [
    "#WITH VALIDATION\n",
    "\n",
    "# If GPU is provided, TFF will by default use the first GPU like TF. The\n",
    "# following lines will configure TFF to use multi-GPUs and distribute client\n",
    "# computation on the GPUs. Note that we put server computatoin on CPU to avoid\n",
    "# potential out of memory issue when a large number of clients is sampled per\n",
    "# round. The client devices below can be an empty list when no GPU could be\n",
    "# detected by TF.\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "client_devices = tf.config.list_logical_devices('GPU')\n",
    "server_device = tf.config.list_logical_devices('CPU')[0]\n",
    "tff.backends.native.set_local_python_execution_context(\n",
    "    server_tf_device=server_device, client_tf_devices=client_devices)\n",
    "train_data, valid_data = get_custom_dataset()\n",
    "def tff_model_fn():\n",
    "  \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "  keras_model = create_fedavg_model(only_digits=True)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "  metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      loss=loss,\n",
    "      metrics=metrics,\n",
    "      input_spec=train_data.element_type_structure)\n",
    "\n",
    "iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "    tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "server_state = iterative_process.initialize()\n",
    "# Keras model that represents the global model we'll evaluate test data on.\n",
    "keras_model = create_fedavg_model(only_digits=True)\n",
    "for round_num in range(TOTAL_ROUNDS):\n",
    "  sampled_clients = np.random.choice(\n",
    "      train_data.client_ids,\n",
    "      size=TRAIN_CLIENTS_PER_ROUND,\n",
    "      replace=False)\n",
    "  sampled_train_data = [\n",
    "      train_data.create_tf_dataset_for_client(client)\n",
    "      for client in sampled_clients\n",
    "  ]\n",
    "  server_state, train_metrics = iterative_process.next(\n",
    "      server_state, sampled_train_data)\n",
    "  print(f'Round {round_num}')\n",
    "  print(f'\\tTraining metrics: {train_metrics}')\n",
    "  train_loss_list.append(train_metrics.get('loss'))\n",
    "\n",
    "  if round_num % ROUNDS_PER_EVAL == 0:\n",
    "    server_state.model.assign_weights_to(keras_model)\n",
    "    val_loss = evaluate(keras_model, valid_data)\n",
    "    val_loss_list.append(val_loss)\n",
    "    print(f'\\tValidation loss: {val_loss: .7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe761f11190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list, label=\"Training Loss\")\n",
    "plt.plot(val_loss_list, label=\"Validation Loss\")\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "  reconstructions = model(data)\n",
    "  return reconstructions\n",
    "\n",
    "def get_accuracy_list(dict):\n",
    "  acc_list = []\n",
    "  for i in range(0,NUM_CLIENTS):\n",
    "    df_cl = pd.DataFrame.from_dict(dict[str(i)]).copy()\n",
    "    tmp_labels = df_cl.pop('label')\n",
    "    preds = predict(keras_model, np.array(df_cl))\n",
    "    acc_list.append(accuracy_score(tmp_labels.astype(int), np.round(preds[:,1], decimals=0)))\n",
    "  return acc_list\n",
    "    \n",
    "\n",
    "def print_stats(predictions, labels):\n",
    "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
    "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
    "  print(\"Recall = {}\".format(recall_score(labels, predictions))) #sensitivity\n",
    "  print(\"F1 = {}\".format(f1_score(labels, predictions)))\n",
    "  print(\"ROC_AUC = {}\".format(roc_auc_score(labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9560439560439561\n",
      "Precision = 0.927536231884058\n",
      "Recall = 0.9552238805970149\n",
      "F1 = 0.9411764705882353\n",
      "ROC_AUC = 0.9558728098637249\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame.from_dict(test_cl_dict[str(np.random.randint(0,NUM_CLIENTS-1))]).copy()\n",
    "labs = test.pop('label')\n",
    "preds = predict(keras_model, np.array(test))\n",
    "print_stats(np.round(preds[:,1], decimals=0), labs.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_list = get_accuracy_list(test_cl_dict)\n",
    "\n",
    "plt.hist(acc_list, bins=30)\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71c52cf81b3ce176a2dee7a24d4a513c23ffb6ff815f0de53fd7e035b7d8234"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
