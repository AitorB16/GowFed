{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 06:02:43.447893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-14 06:02:43.447924: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tester/Desktop/TF/TFF', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/home/tester/venv/lib/python3.9/site-packages', '/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg']\n",
      "['/home/tester/Desktop/TF/TFF', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/home/tester/venv/lib/python3.9/site-packages', '/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg', '/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "import collections\n",
    "\n",
    "from absl import app\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "\n",
    "from keras.backend import print_tensor\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg\")\n",
    "print(sys.path)\n",
    "import simple_fedavg_tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "TOTAL_ROUNDS = 350 #NUMBER OF TOTAL TRAINING ROUNDS\n",
    "ROUNDS_PER_EVAL = 1 #HOW OFTEN TO EVALUATE\n",
    "TRAIN_CLIENTS_PER_ROUND = 6 #HOW MANY CLIENTS TO SAMPLE PER ROUND\n",
    "CLIENT_EPOCHS_PER_ROUND = 2 #NUMBER OF EPOCHS IN THE CLIENT TO TAKE PER ROUND\n",
    "BATCH_SIZE = 256 #BATCH SIZE USED ON THE CLIENT\n",
    "TEST_BATCH_SIZE = 64 #MINIBATCH SIZE OF TEST DATA\n",
    "SERVER_LEARNING_RATE = 0.001 #SERVER LEARNING RATE\n",
    "CLIENT_LEARNING_RATE = 0.00001 #CLIENT LEARNING RATE\n",
    "NUM_CLIENTS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/TON_IoT-Datasets/Train_Test_datasets/Train_Test_IoT_dataset/Train_Test_IoT_Modbus.csv\")\n",
    "df.head()\n",
    "reduced_df = df[[\"FC1_Read_Input_Register\", \"FC2_Read_Discrete_Value\", \"FC3_Read_Holding_Register\", \"FC4_Read_Coil\", \"label\"]]\n",
    "df = reduced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3151489061949673\n"
     ]
    }
   ],
   "source": [
    "# Percentage malware\n",
    "perc = len(df.loc[df['label']==1])/len(df)\n",
    "print(perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Balance dataset\n",
    "num_anom = len(df.loc[df['label']==1])\n",
    "df_anom = df.loc[df['label']==1]\n",
    "df_normal = df.loc[df['label']==0]\n",
    "df_normal = df_normal.sample(num_anom, replace=False)\n",
    "df_concated = pd.concat([df_normal, df_anom])\n",
    "df = df_concated\n",
    "\n",
    "# Percentage malware\n",
    "perc = len(df.loc[df['label']==1])/len(df)\n",
    "print(perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "data_scaled = df.copy()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "#data_scaled[[\"src_port\", \"dst_port\", \"src_bytes\", \"dst_bytes\", \"missed_bytes\"]] = min_max_scaler.fit_transform(data_scaled[[\"src_port\", \"dst_port\", \"src_bytes\", \"dst_bytes\", \"missed_bytes\"]])\n",
    "data_scaled[data_scaled.columns] = min_max_scaler.fit_transform(data_scaled[data_scaled.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FC1_Read_Input_Register</th>\n",
       "      <th>FC2_Read_Discrete_Value</th>\n",
       "      <th>FC3_Read_Holding_Register</th>\n",
       "      <th>FC4_Read_Coil</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>0.555160</td>\n",
       "      <td>0.756191</td>\n",
       "      <td>0.506799</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.599783</td>\n",
       "      <td>0.409766</td>\n",
       "      <td>0.804182</td>\n",
       "      <td>0.069369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12565</th>\n",
       "      <td>0.514200</td>\n",
       "      <td>0.720516</td>\n",
       "      <td>0.310248</td>\n",
       "      <td>0.139332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14903</th>\n",
       "      <td>0.447480</td>\n",
       "      <td>0.712459</td>\n",
       "      <td>0.604212</td>\n",
       "      <td>0.420728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9816</th>\n",
       "      <td>0.830146</td>\n",
       "      <td>0.421149</td>\n",
       "      <td>0.442228</td>\n",
       "      <td>0.118107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FC1_Read_Input_Register  FC2_Read_Discrete_Value  \\\n",
       "13342                 0.555160                 0.756191   \n",
       "1030                  0.599783                 0.409766   \n",
       "12565                 0.514200                 0.720516   \n",
       "14903                 0.447480                 0.712459   \n",
       "9816                  0.830146                 0.421149   \n",
       "\n",
       "       FC3_Read_Holding_Register  FC4_Read_Coil  label  \n",
       "13342                   0.506799       0.370220      1  \n",
       "1030                    0.804182       0.069369      1  \n",
       "12565                   0.310248       0.139332      1  \n",
       "14903                   0.604212       0.420728      1  \n",
       "9816                    0.442228       0.118107      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data_scaled, test_size=0.2)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separe normal and anomaly classes\n",
    "train_labels = train['label'].astype(bool).copy()\n",
    "test_labels = test['label'].astype(bool).copy()\n",
    "\n",
    "normal_train_data = train[~train_labels]\n",
    "normal_test_data = test[~test_labels]\n",
    "\n",
    "anomalous_train_data = train[train_labels]\n",
    "anomalous_test_data = test[test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#IID or NOIID? SPLIT DATA AMONG CLIENTS\n",
    "client_id = np.random.choice(range(NUM_CLIENTS), size=len(normal_train_data), replace=True)\n",
    "#df['client_id'] = client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN: Create a dict where keys are client ids format for tff.simulation.datasets.TestClientData\n",
    "normal_train_cl_dict = {}\n",
    "for id in range(NUM_CLIENTS):\n",
    "    tmp_train_df = normal_train_data.loc[client_id == id]\n",
    "    tmp_train_dict = {name: np.array(value) \n",
    "                         for name, value in tmp_train_df.items()}\n",
    "    normal_train_cl_dict[str(id)]=tmp_train_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine max_client_ds_size\n",
    "max_client_ds_size = -1\n",
    "for id in range(NUM_CLIENTS):\n",
    "    tmp_len = len(normal_train_data.loc[client_id == id])\n",
    "    if(tmp_len > max_client_ds_size):\n",
    "        max_client_ds_size = tmp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "tmp_test_dict = {name: np.array(value)\n",
    "    for name, value in normal_test_data.items()}\n",
    "normal_test_cl_dict = {'0': tmp_test_dict}\n",
    "normal_test_ds_size = len(normal_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 06:02:46.291646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-14 06:02:46.291677: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-14 06:02:46.291694: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debian): /proc/driver/nvidia/version does not exist\n",
      "2022-06-14 06:02:46.291903: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#CONVERT TO TFF DATASET\n",
    "#netw_ds = tf.data.Dataset.from_tensor_slices((netw_features_dict, netw_labels))\n",
    "#netw_ds = tf.data.Dataset.from_tensor_slices(netw_features_dict)\n",
    "normal_train_fd_ds = tff.simulation.datasets.TestClientData(normal_train_cl_dict)\n",
    "normal_test_fd_ds = tff.simulation.datasets.TestClientData(normal_test_cl_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FedAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(keras_model, test_dataset):\n",
    "  \"\"\"Evaluate the acurracy of a keras model on a test dataset.\"\"\"\n",
    "  #metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "  metric = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "  for batch in test_dataset:\n",
    "    #DONT KNOW WHAT DOES\n",
    "    predictions = keras_model(batch['x'])\n",
    "    metric.update_state(y_true=batch['y'], y_pred=predictions)\n",
    "  return metric.result()\n",
    "\n",
    "def get_custom_dataset():\n",
    "  def element_fn(element):\n",
    "    features = tf.convert_to_tensor([element[\"FC1_Read_Input_Register\"], element[\"FC2_Read_Discrete_Value\"], element[\"FC3_Read_Holding_Register\"], element[\"FC4_Read_Coil\"]], dtype=tf.float32)\n",
    "    #features = tf.convert_to_tensor([element[\"FC1_Read_Input_Register\"], element[\"FC2_Read_Discrete_Value\"]], dtype=tf.float32)\n",
    "    #print_tensor(features)\n",
    "    return collections.OrderedDict(\n",
    "      # tf.expand_dims? ADD MORE COLUMNS\n",
    "        x=features, y=element['label'])\n",
    "\n",
    "  def preprocess_train_dataset(dataset):\n",
    "    # Use buffer_size same as the maximum client dataset size,\n",
    "    return dataset.map(element_fn).shuffle(buffer_size=max_client_ds_size).repeat(\n",
    "        count=CLIENT_EPOCHS_PER_ROUND).batch(\n",
    "            BATCH_SIZE, drop_remainder=False)\n",
    "  def preprocess_test_dataset(dataset):\n",
    "    return dataset.map(element_fn).batch(\n",
    "        TEST_BATCH_SIZE, drop_remainder=False)\n",
    "  netw_train = normal_train_fd_ds.preprocess(preprocess_train_dataset)\n",
    "  netw_test = preprocess_test_dataset(\n",
    "      normal_test_fd_ds.create_tf_dataset_from_all_clients())\n",
    "  return netw_train, netw_test\n",
    "\n",
    "\n",
    "def create_fedavg_model(only_digits=True):\n",
    "  \"\"\"The CNN model used in https://arxiv.org/abs/1602.05629.\n",
    "\n",
    "  Args:\n",
    "    only_digits: If True, uses a final layer with 10 outputs, for use with the\n",
    "      digits only EMNIST dataset. If False, uses 62 outputs for the larger\n",
    "      dataset.\n",
    "\n",
    "  Returns:\n",
    "    An uncompiled `tf.keras.Model`.\n",
    "  \"\"\"\n",
    "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(2, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "\n",
    "def server_optimizer_fn():\n",
    "  return tf.keras.optimizers.Adam(learning_rate=SERVER_LEARNING_RATE)\n",
    "\n",
    "\n",
    "def client_optimizer_fn():\n",
    "  return tf.keras.optimizers.Adam(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3782827), ('num_examples', 3070), ('num_batches', 14)])\n",
      "\tValidation loss:  1.3661998510360718\n",
      "Round 1\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3754873), ('num_examples', 3162), ('num_batches', 16)])\n",
      "\tValidation loss:  1.3607884645462036\n",
      "Round 2\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3724794), ('num_examples', 3164), ('num_batches', 16)])\n",
      "\tValidation loss:  1.3551411628723145\n",
      "Round 3\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3697572), ('num_examples', 3130), ('num_batches', 16)])\n",
      "\tValidation loss:  1.3492884635925293\n",
      "Round 4\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3663739), ('num_examples', 3098), ('num_batches', 15)])\n",
      "\tValidation loss:  1.3432540893554688\n",
      "Round 5\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3632569), ('num_examples', 3098), ('num_batches', 15)])\n",
      "\tValidation loss:  1.3370329141616821\n",
      "Round 6\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3599375), ('num_examples', 3064), ('num_batches', 14)])\n",
      "\tValidation loss:  1.3306474685668945\n",
      "Round 7\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3562933), ('num_examples', 3236), ('num_batches', 17)])\n",
      "\tValidation loss:  1.3240182399749756\n",
      "Round 8\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3525218), ('num_examples', 2968), ('num_batches', 14)])\n",
      "\tValidation loss:  1.3171957731246948\n",
      "Round 9\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3491462), ('num_examples', 3124), ('num_batches', 16)])\n",
      "\tValidation loss:  1.3100967407226562\n",
      "Round 10\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3451478), ('num_examples', 2942), ('num_batches', 14)])\n",
      "\tValidation loss:  1.3027473688125610\n",
      "Round 11\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3411837), ('num_examples', 3048), ('num_batches', 15)])\n",
      "\tValidation loss:  1.2950803041458130\n",
      "Round 12\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3371122), ('num_examples', 3010), ('num_batches', 15)])\n",
      "\tValidation loss:  1.2871392965316772\n",
      "Round 13\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3320974), ('num_examples', 3232), ('num_batches', 17)])\n",
      "\tValidation loss:  1.2789433002471924\n",
      "Round 14\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3275739), ('num_examples', 3156), ('num_batches', 16)])\n",
      "\tValidation loss:  1.2705547809600830\n",
      "Round 15\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3235742), ('num_examples', 3170), ('num_batches', 16)])\n",
      "\tValidation loss:  1.2619777917861938\n",
      "Round 16\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3175064), ('num_examples', 3104), ('num_batches', 15)])\n",
      "\tValidation loss:  1.2532483339309692\n",
      "Round 17\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3124713), ('num_examples', 3158), ('num_batches', 16)])\n",
      "\tValidation loss:  1.2443344593048096\n",
      "Round 18\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3076795), ('num_examples', 3138), ('num_batches', 15)])\n",
      "\tValidation loss:  1.2352741956710815\n",
      "Round 19\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3029474), ('num_examples', 3246), ('num_batches', 18)])\n",
      "\tValidation loss:  1.2259813547134399\n",
      "Round 20\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2976782), ('num_examples', 3056), ('num_batches', 14)])\n",
      "\tValidation loss:  1.2165936231613159\n",
      "Round 21\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2913259), ('num_examples', 3126), ('num_batches', 16)])\n",
      "\tValidation loss:  1.2070291042327881\n",
      "Round 22\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2862946), ('num_examples', 3100), ('num_batches', 14)])\n",
      "\tValidation loss:  1.1973761320114136\n",
      "Round 23\n",
      "\tTraining metrics: OrderedDict([('loss', 1.28072), ('num_examples', 3140), ('num_batches', 15)])\n",
      "\tValidation loss:  1.1875910758972168\n",
      "Round 24\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2748885), ('num_examples', 3082), ('num_batches', 15)])\n",
      "\tValidation loss:  1.1776840686798096\n",
      "Round 25\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2675455), ('num_examples', 2970), ('num_batches', 14)])\n",
      "\tValidation loss:  1.1677025556564331\n",
      "Round 26\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2628502), ('num_examples', 3078), ('num_batches', 15)])\n",
      "\tValidation loss:  1.1576026678085327\n",
      "Round 27\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2557869), ('num_examples', 3080), ('num_batches', 15)])\n",
      "\tValidation loss:  1.1473921537399292\n",
      "Round 28\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2502046), ('num_examples', 3010), ('num_batches', 15)])\n",
      "\tValidation loss:  1.1370856761932373\n",
      "Round 29\n",
      "\tTraining metrics: OrderedDict([('loss', 1.244697), ('num_examples', 3148), ('num_batches', 16)])\n",
      "\tValidation loss:  1.1266305446624756\n",
      "Round 30\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2368817), ('num_examples', 3144), ('num_batches', 16)])\n",
      "\tValidation loss:  1.1160260438919067\n",
      "Round 31\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2317619), ('num_examples', 3088), ('num_batches', 15)])\n",
      "\tValidation loss:  1.1053121089935303\n",
      "Round 32\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2235992), ('num_examples', 3182), ('num_batches', 17)])\n",
      "\tValidation loss:  1.0943994522094727\n",
      "Round 33\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2158594), ('num_examples', 3032), ('num_batches', 14)])\n",
      "\tValidation loss:  1.0834408998489380\n",
      "Round 34\n",
      "\tTraining metrics: OrderedDict([('loss', 1.20969), ('num_examples', 3200), ('num_batches', 17)])\n",
      "\tValidation loss:  1.0722903013229370\n",
      "Round 35\n",
      "\tTraining metrics: OrderedDict([('loss', 1.203356), ('num_examples', 3234), ('num_batches', 17)])\n",
      "\tValidation loss:  1.0609612464904785\n",
      "Round 36\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1948472), ('num_examples', 3080), ('num_batches', 15)])\n",
      "\tValidation loss:  1.0495631694793701\n",
      "Round 37\n",
      "\tTraining metrics: OrderedDict([('loss', 1.18817), ('num_examples', 3088), ('num_batches', 15)])\n",
      "\tValidation loss:  1.0381122827529907\n",
      "Round 38\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1791222), ('num_examples', 3024), ('num_batches', 14)])\n",
      "\tValidation loss:  1.0266621112823486\n",
      "Round 39\n",
      "\tTraining metrics: OrderedDict([('loss', 1.170089), ('num_examples', 3118), ('num_batches', 17)])\n",
      "\tValidation loss:  1.0150389671325684\n",
      "Round 40\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1649144), ('num_examples', 3044), ('num_batches', 15)])\n",
      "\tValidation loss:  1.0033317804336548\n",
      "Round 41\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1550333), ('num_examples', 3038), ('num_batches', 15)])\n",
      "\tValidation loss:  0.9915305376052856\n",
      "Round 42\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1488415), ('num_examples', 3092), ('num_batches', 15)])\n",
      "\tValidation loss:  0.9796336889266968\n",
      "Round 43\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1403077), ('num_examples', 3034), ('num_batches', 15)])\n",
      "\tValidation loss:  0.9676428437232971\n",
      "Round 44\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1310767), ('num_examples', 3156), ('num_batches', 16)])\n",
      "\tValidation loss:  0.9555072784423828\n",
      "Round 45\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1217753), ('num_examples', 3028), ('num_batches', 15)])\n",
      "\tValidation loss:  0.9432899951934814\n",
      "Round 46\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1153919), ('num_examples', 2834), ('num_batches', 12)])\n",
      "\tValidation loss:  0.9312196969985962\n",
      "Round 47\n",
      "\tTraining metrics: OrderedDict([('loss', 1.1031463), ('num_examples', 3018), ('num_batches', 15)])\n",
      "\tValidation loss:  0.9190411567687988\n",
      "Round 48\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0979893), ('num_examples', 3130), ('num_batches', 16)])\n",
      "\tValidation loss:  0.9067041873931885\n",
      "Round 49\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0882839), ('num_examples', 3104), ('num_batches', 15)])\n",
      "\tValidation loss:  0.8942735791206360\n",
      "Round 50\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0787293), ('num_examples', 3100), ('num_batches', 15)])\n",
      "\tValidation loss:  0.8817397356033325\n",
      "Round 51\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0711786), ('num_examples', 3180), ('num_batches', 16)])\n",
      "\tValidation loss:  0.8690411448478699\n",
      "Round 52\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0626172), ('num_examples', 3082), ('num_batches', 15)])\n",
      "\tValidation loss:  0.8562492132186890\n",
      "Round 53\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0508314), ('num_examples', 3276), ('num_batches', 17)])\n",
      "\tValidation loss:  0.8432567119598389\n",
      "Round 54\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0418719), ('num_examples', 3054), ('num_batches', 16)])\n",
      "\tValidation loss:  0.8301301598548889\n",
      "Round 55\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0318732), ('num_examples', 3066), ('num_batches', 15)])\n",
      "\tValidation loss:  0.8169395327568054\n",
      "Round 56\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0231161), ('num_examples', 3106), ('num_batches', 16)])\n",
      "\tValidation loss:  0.8036261796951294\n",
      "Round 57\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0108075), ('num_examples', 3122), ('num_batches', 16)])\n",
      "\tValidation loss:  0.7901956439018250\n",
      "Round 58\n",
      "\tTraining metrics: OrderedDict([('loss', 1.002124), ('num_examples', 3052), ('num_batches', 15)])\n",
      "\tValidation loss:  0.7767169475555420\n",
      "Round 59\n",
      "\tTraining metrics: OrderedDict([('loss', 0.9921685), ('num_examples', 3052), ('num_batches', 16)])\n",
      "\tValidation loss:  0.7631287574768066\n",
      "Round 60\n",
      "\tTraining metrics: OrderedDict([('loss', 0.9777871), ('num_examples', 3220), ('num_batches', 17)])\n",
      "\tValidation loss:  0.7493839859962463\n",
      "Round 61\n",
      "\tTraining metrics: OrderedDict([('loss', 0.96906126), ('num_examples', 3200), ('num_batches', 17)])\n",
      "\tValidation loss:  0.7355014681816101\n",
      "Round 62\n",
      "\tTraining metrics: OrderedDict([('loss', 0.9589978), ('num_examples', 3018), ('num_batches', 14)])\n",
      "\tValidation loss:  0.7216900587081909\n",
      "Round 63\n",
      "\tTraining metrics: OrderedDict([('loss', 0.9459892), ('num_examples', 2886), ('num_batches', 13)])\n",
      "\tValidation loss:  0.7080298066139221\n",
      "Round 64\n",
      "\tTraining metrics: OrderedDict([('loss', 0.9390695), ('num_examples', 3000), ('num_batches', 14)])\n",
      "\tValidation loss:  0.6944143176078796\n",
      "Round 65\n",
      "\tTraining metrics: OrderedDict([('loss', 0.92435247), ('num_examples', 3062), ('num_batches', 16)])\n",
      "\tValidation loss:  0.6807013154029846\n",
      "Round 66\n",
      "\tTraining metrics: OrderedDict([('loss', 0.9139315), ('num_examples', 3120), ('num_batches', 17)])\n",
      "\tValidation loss:  0.6668445467948914\n",
      "Round 67\n",
      "\tTraining metrics: OrderedDict([('loss', 0.9039207), ('num_examples', 3228), ('num_batches', 17)])\n",
      "\tValidation loss:  0.6528666019439697\n",
      "Round 68\n",
      "\tTraining metrics: OrderedDict([('loss', 0.8910298), ('num_examples', 3034), ('num_batches', 15)])\n",
      "\tValidation loss:  0.6389093995094299\n",
      "Round 69\n",
      "\tTraining metrics: OrderedDict([('loss', 0.87874407), ('num_examples', 3172), ('num_batches', 16)])\n",
      "\tValidation loss:  0.6249067783355713\n",
      "Round 70\n",
      "\tTraining metrics: OrderedDict([('loss', 0.87077254), ('num_examples', 2982), ('num_batches', 15)])\n",
      "\tValidation loss:  0.6109390854835510\n",
      "Round 71\n",
      "\tTraining metrics: OrderedDict([('loss', 0.8566512), ('num_examples', 3064), ('num_batches', 15)])\n",
      "\tValidation loss:  0.5970125794410706\n",
      "Round 72\n",
      "\tTraining metrics: OrderedDict([('loss', 0.84593123), ('num_examples', 3072), ('num_batches', 15)])\n",
      "\tValidation loss:  0.5831294655799866\n",
      "Round 73\n",
      "\tTraining metrics: OrderedDict([('loss', 0.8339325), ('num_examples', 3074), ('num_batches', 15)])\n",
      "\tValidation loss:  0.5692908167839050\n",
      "Round 74\n",
      "\tTraining metrics: OrderedDict([('loss', 0.8225956), ('num_examples', 3074), ('num_batches', 14)])\n",
      "\tValidation loss:  0.5555852651596069\n",
      "Round 75\n",
      "\tTraining metrics: OrderedDict([('loss', 0.80914146), ('num_examples', 3210), ('num_batches', 15)])\n",
      "\tValidation loss:  0.5419261455535889\n",
      "Round 76\n",
      "\tTraining metrics: OrderedDict([('loss', 0.797307), ('num_examples', 3046), ('num_batches', 14)])\n",
      "\tValidation loss:  0.5283986926078796\n",
      "Round 77\n",
      "\tTraining metrics: OrderedDict([('loss', 0.78380597), ('num_examples', 3064), ('num_batches', 15)])\n",
      "\tValidation loss:  0.5149227380752563\n",
      "Round 78\n",
      "\tTraining metrics: OrderedDict([('loss', 0.7750623), ('num_examples', 2814), ('num_batches', 12)])\n",
      "\tValidation loss:  0.5017811655998230\n",
      "Round 79\n",
      "\tTraining metrics: OrderedDict([('loss', 0.7618995), ('num_examples', 3084), ('num_batches', 14)])\n",
      "\tValidation loss:  0.4887518584728241\n",
      "Round 80\n",
      "\tTraining metrics: OrderedDict([('loss', 0.74852324), ('num_examples', 2988), ('num_batches', 14)])\n",
      "\tValidation loss:  0.4758393168449402\n",
      "Round 81\n",
      "\tTraining metrics: OrderedDict([('loss', 0.73930573), ('num_examples', 3072), ('num_batches', 14)])\n",
      "\tValidation loss:  0.4630433320999146\n",
      "Round 82\n",
      "\tTraining metrics: OrderedDict([('loss', 0.7229897), ('num_examples', 2860), ('num_batches', 13)])\n",
      "\tValidation loss:  0.4504536688327789\n",
      "Round 83\n",
      "\tTraining metrics: OrderedDict([('loss', 0.71387976), ('num_examples', 3010), ('num_batches', 14)])\n",
      "\tValidation loss:  0.4379735291004181\n",
      "Round 84\n",
      "\tTraining metrics: OrderedDict([('loss', 0.70289695), ('num_examples', 3122), ('num_batches', 16)])\n",
      "\tValidation loss:  0.4254664480686188\n",
      "Round 85\n",
      "\tTraining metrics: OrderedDict([('loss', 0.68997), ('num_examples', 3228), ('num_batches', 17)])\n",
      "\tValidation loss:  0.4128989875316620\n",
      "Round 86\n",
      "\tTraining metrics: OrderedDict([('loss', 0.6800194), ('num_examples', 3050), ('num_batches', 14)])\n",
      "\tValidation loss:  0.4004941582679749\n",
      "Round 87\n",
      "\tTraining metrics: OrderedDict([('loss', 0.6679971), ('num_examples', 3066), ('num_batches', 15)])\n",
      "\tValidation loss:  0.3881827294826508\n",
      "Round 88\n",
      "\tTraining metrics: OrderedDict([('loss', 0.6559182), ('num_examples', 2972), ('num_batches', 14)])\n",
      "\tValidation loss:  0.3760482370853424\n",
      "Round 89\n",
      "\tTraining metrics: OrderedDict([('loss', 0.6477108), ('num_examples', 3046), ('num_batches', 15)])\n",
      "\tValidation loss:  0.3640198409557343\n",
      "Round 90\n",
      "\tTraining metrics: OrderedDict([('loss', 0.63324857), ('num_examples', 3100), ('num_batches', 15)])\n",
      "\tValidation loss:  0.3521093726158142\n",
      "Round 91\n",
      "\tTraining metrics: OrderedDict([('loss', 0.6238939), ('num_examples', 3162), ('num_batches', 16)])\n",
      "\tValidation loss:  0.3402690589427948\n",
      "Round 92\n",
      "\tTraining metrics: OrderedDict([('loss', 0.6098534), ('num_examples', 3080), ('num_batches', 14)])\n",
      "\tValidation loss:  0.3286560475826263\n",
      "Round 93\n",
      "\tTraining metrics: OrderedDict([('loss', 0.59351087), ('num_examples', 3020), ('num_batches', 15)])\n",
      "\tValidation loss:  0.3172606527805328\n",
      "Round 94\n",
      "\tTraining metrics: OrderedDict([('loss', 0.5850414), ('num_examples', 3120), ('num_batches', 16)])\n",
      "\tValidation loss:  0.3060331046581268\n",
      "Round 95\n",
      "\tTraining metrics: OrderedDict([('loss', 0.5725191), ('num_examples', 2988), ('num_batches', 14)])\n",
      "\tValidation loss:  0.2951041162014008\n",
      "Round 96\n",
      "\tTraining metrics: OrderedDict([('loss', 0.5631411), ('num_examples', 3312), ('num_batches', 17)])\n",
      "\tValidation loss:  0.2843030989170074\n",
      "Round 97\n",
      "\tTraining metrics: OrderedDict([('loss', 0.54951906), ('num_examples', 3050), ('num_batches', 16)])\n",
      "\tValidation loss:  0.2736890912055969\n",
      "Round 98\n",
      "\tTraining metrics: OrderedDict([('loss', 0.5395026), ('num_examples', 3236), ('num_batches', 17)])\n",
      "\tValidation loss:  0.2632261216640472\n",
      "Round 99\n",
      "\tTraining metrics: OrderedDict([('loss', 0.52724355), ('num_examples', 3152), ('num_batches', 16)])\n",
      "\tValidation loss:  0.2529714405536652\n",
      "Round 100\n",
      "\tTraining metrics: OrderedDict([('loss', 0.5137891), ('num_examples', 3042), ('num_batches', 15)])\n",
      "\tValidation loss:  0.2429775595664978\n",
      "Round 101\n",
      "\tTraining metrics: OrderedDict([('loss', 0.50384873), ('num_examples', 3102), ('num_batches', 16)])\n",
      "\tValidation loss:  0.2331915646791458\n",
      "Round 102\n",
      "\tTraining metrics: OrderedDict([('loss', 0.4932155), ('num_examples', 3188), ('num_batches', 15)])\n",
      "\tValidation loss:  0.2236648201942444\n",
      "Round 103\n",
      "\tTraining metrics: OrderedDict([('loss', 0.4779317), ('num_examples', 3208), ('num_batches', 17)])\n",
      "\tValidation loss:  0.2143109142780304\n",
      "Round 104\n",
      "\tTraining metrics: OrderedDict([('loss', 0.46829864), ('num_examples', 3022), ('num_batches', 15)])\n",
      "\tValidation loss:  0.2052244991064072\n",
      "Round 105\n",
      "\tTraining metrics: OrderedDict([('loss', 0.45971775), ('num_examples', 3248), ('num_batches', 17)])\n",
      "\tValidation loss:  0.1963189244270325\n",
      "Round 106\n",
      "\tTraining metrics: OrderedDict([('loss', 0.44535685), ('num_examples', 2994), ('num_batches', 14)])\n",
      "\tValidation loss:  0.1877573430538177\n",
      "Round 107\n",
      "\tTraining metrics: OrderedDict([('loss', 0.43477035), ('num_examples', 3052), ('num_batches', 16)])\n",
      "\tValidation loss:  0.1794394105672836\n",
      "Round 108\n",
      "\tTraining metrics: OrderedDict([('loss', 0.42203927), ('num_examples', 3078), ('num_batches', 15)])\n",
      "\tValidation loss:  0.1714056432247162\n",
      "Round 109\n",
      "\tTraining metrics: OrderedDict([('loss', 0.41037345), ('num_examples', 2998), ('num_batches', 15)])\n",
      "\tValidation loss:  0.1636475175619125\n",
      "Round 110\n",
      "\tTraining metrics: OrderedDict([('loss', 0.401175), ('num_examples', 3152), ('num_batches', 16)])\n",
      "\tValidation loss:  0.1561194658279419\n",
      "Round 111\n",
      "\tTraining metrics: OrderedDict([('loss', 0.38959295), ('num_examples', 3002), ('num_batches', 15)])\n",
      "\tValidation loss:  0.1488544642925262\n",
      "Round 112\n",
      "\tTraining metrics: OrderedDict([('loss', 0.38035724), ('num_examples', 3076), ('num_batches', 16)])\n",
      "\tValidation loss:  0.1418096721172333\n",
      "Round 113\n",
      "\tTraining metrics: OrderedDict([('loss', 0.3675165), ('num_examples', 3000), ('num_batches', 13)])\n",
      "\tValidation loss:  0.1351003497838974\n",
      "Round 114\n",
      "\tTraining metrics: OrderedDict([('loss', 0.3592061), ('num_examples', 3074), ('num_batches', 15)])\n",
      "\tValidation loss:  0.1286236643791199\n",
      "Round 115\n",
      "\tTraining metrics: OrderedDict([('loss', 0.34502462), ('num_examples', 3030), ('num_batches', 14)])\n",
      "\tValidation loss:  0.1224093139171600\n",
      "Round 116\n",
      "\tTraining metrics: OrderedDict([('loss', 0.3376493), ('num_examples', 3138), ('num_batches', 15)])\n",
      "\tValidation loss:  0.1164105311036110\n",
      "Round 117\n",
      "\tTraining metrics: OrderedDict([('loss', 0.32661912), ('num_examples', 2984), ('num_batches', 15)])\n",
      "\tValidation loss:  0.1106236875057220\n",
      "Round 118\n",
      "\tTraining metrics: OrderedDict([('loss', 0.31699443), ('num_examples', 3198), ('num_batches', 16)])\n",
      "\tValidation loss:  0.1050166040658951\n",
      "Round 119\n",
      "\tTraining metrics: OrderedDict([('loss', 0.30850065), ('num_examples', 3242), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0995679572224617\n",
      "Round 120\n",
      "\tTraining metrics: OrderedDict([('loss', 0.2982852), ('num_examples', 3126), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0943325981497765\n",
      "Round 121\n",
      "\tTraining metrics: OrderedDict([('loss', 0.2884189), ('num_examples', 3118), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0892810598015785\n",
      "Round 122\n",
      "\tTraining metrics: OrderedDict([('loss', 0.27723962), ('num_examples', 3182), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0844128429889679\n",
      "Round 123\n",
      "\tTraining metrics: OrderedDict([('loss', 0.26875725), ('num_examples', 3174), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0797277092933655\n",
      "Round 124\n",
      "\tTraining metrics: OrderedDict([('loss', 0.26087227), ('num_examples', 3118), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0752245187759399\n",
      "Round 125\n",
      "\tTraining metrics: OrderedDict([('loss', 0.25083053), ('num_examples', 3118), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0709230750799179\n",
      "Round 126\n",
      "\tTraining metrics: OrderedDict([('loss', 0.23821461), ('num_examples', 3238), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0667785704135895\n",
      "Round 127\n",
      "\tTraining metrics: OrderedDict([('loss', 0.23244971), ('num_examples', 3142), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0628307163715363\n",
      "Round 128\n",
      "\tTraining metrics: OrderedDict([('loss', 0.2221661), ('num_examples', 3180), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0590529218316078\n",
      "Round 129\n",
      "\tTraining metrics: OrderedDict([('loss', 0.21622449), ('num_examples', 3180), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0554272755980492\n",
      "Round 130\n",
      "\tTraining metrics: OrderedDict([('loss', 0.20378907), ('num_examples', 3094), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0519693903625011\n",
      "Round 131\n",
      "\tTraining metrics: OrderedDict([('loss', 0.19526488), ('num_examples', 3186), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0486613363027573\n",
      "Round 132\n",
      "\tTraining metrics: OrderedDict([('loss', 0.18753344), ('num_examples', 3096), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0455165356397629\n",
      "Round 133\n",
      "\tTraining metrics: OrderedDict([('loss', 0.17966329), ('num_examples', 2994), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0425810366868973\n",
      "Round 134\n",
      "\tTraining metrics: OrderedDict([('loss', 0.16968), ('num_examples', 3108), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0398025959730148\n",
      "Round 135\n",
      "\tTraining metrics: OrderedDict([('loss', 0.16233097), ('num_examples', 3216), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0371501669287682\n",
      "Round 136\n",
      "\tTraining metrics: OrderedDict([('loss', 0.15721457), ('num_examples', 3168), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0346466526389122\n",
      "Round 137\n",
      "\tTraining metrics: OrderedDict([('loss', 0.14978628), ('num_examples', 3164), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0322721600532532\n",
      "Round 138\n",
      "\tTraining metrics: OrderedDict([('loss', 0.14202811), ('num_examples', 3070), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0300224013626575\n",
      "Round 139\n",
      "\tTraining metrics: OrderedDict([('loss', 0.13265881), ('num_examples', 3000), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0279042180627584\n",
      "Round 140\n",
      "\tTraining metrics: OrderedDict([('loss', 0.12470121), ('num_examples', 3086), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0259117316454649\n",
      "Round 141\n",
      "\tTraining metrics: OrderedDict([('loss', 0.12070864), ('num_examples', 2976), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0240501444786787\n",
      "Round 142\n",
      "\tTraining metrics: OrderedDict([('loss', 0.11396723), ('num_examples', 3078), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0223101601004601\n",
      "Round 143\n",
      "\tTraining metrics: OrderedDict([('loss', 0.1095778), ('num_examples', 3082), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0206723120063543\n",
      "Round 144\n",
      "\tTraining metrics: OrderedDict([('loss', 0.101791), ('num_examples', 3200), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0191197022795677\n",
      "Round 145\n",
      "\tTraining metrics: OrderedDict([('loss', 0.09742607), ('num_examples', 3200), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0176396705210209\n",
      "Round 146\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0915641), ('num_examples', 3148), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0162313673645258\n",
      "Round 147\n",
      "\tTraining metrics: OrderedDict([('loss', 0.085616626), ('num_examples', 3064), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0148960696533322\n",
      "Round 148\n",
      "\tTraining metrics: OrderedDict([('loss', 0.08145258), ('num_examples', 3182), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0136474873870611\n",
      "Round 149\n",
      "\tTraining metrics: OrderedDict([('loss', 0.075024724), ('num_examples', 3018), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0124967489391565\n",
      "Round 150\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0701154), ('num_examples', 3124), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0114299915730953\n",
      "Round 151\n",
      "\tTraining metrics: OrderedDict([('loss', 0.06642011), ('num_examples', 3154), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0104371020570397\n",
      "Round 152\n",
      "\tTraining metrics: OrderedDict([('loss', 0.062346283), ('num_examples', 3000), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0095247365534306\n",
      "Round 153\n",
      "\tTraining metrics: OrderedDict([('loss', 0.059467506), ('num_examples', 3030), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0086773112416267\n",
      "Round 154\n",
      "\tTraining metrics: OrderedDict([('loss', 0.054443035), ('num_examples', 3092), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0078957481309772\n",
      "Round 155\n",
      "\tTraining metrics: OrderedDict([('loss', 0.04956941), ('num_examples', 3180), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0071688960306346\n",
      "Round 156\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0472717), ('num_examples', 2908), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0065051182173193\n",
      "Round 157\n",
      "\tTraining metrics: OrderedDict([('loss', 0.042847075), ('num_examples', 3126), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0058923605829477\n",
      "Round 158\n",
      "\tTraining metrics: OrderedDict([('loss', 0.040621985), ('num_examples', 3238), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0053254622034729\n",
      "Round 159\n",
      "\tTraining metrics: OrderedDict([('loss', 0.03794972), ('num_examples', 3342), ('num_batches', 18)])\n",
      "\tValidation loss:  0.0048005669377744\n",
      "Round 160\n",
      "\tTraining metrics: OrderedDict([('loss', 0.03553127), ('num_examples', 3092), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0043254494667053\n",
      "Round 161\n",
      "\tTraining metrics: OrderedDict([('loss', 0.03207527), ('num_examples', 3132), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0038907013367862\n",
      "Round 162\n",
      "\tTraining metrics: OrderedDict([('loss', 0.029927168), ('num_examples', 3164), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0034937073942274\n",
      "Round 163\n",
      "\tTraining metrics: OrderedDict([('loss', 0.027203955), ('num_examples', 3238), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0031318333931267\n",
      "Round 164\n",
      "\tTraining metrics: OrderedDict([('loss', 0.025572332), ('num_examples', 3094), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0028061093762517\n",
      "Round 165\n",
      "\tTraining metrics: OrderedDict([('loss', 0.022626532), ('num_examples', 3194), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0025112456642091\n",
      "Round 166\n",
      "\tTraining metrics: OrderedDict([('loss', 0.021324508), ('num_examples', 3090), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0022433181293309\n",
      "Round 167\n",
      "\tTraining metrics: OrderedDict([('loss', 0.019701052), ('num_examples', 3084), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0020004415418953\n",
      "Round 168\n",
      "\tTraining metrics: OrderedDict([('loss', 0.017545808), ('num_examples', 3038), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0017844516551122\n",
      "Round 169\n",
      "\tTraining metrics: OrderedDict([('loss', 0.01647461), ('num_examples', 3098), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0015896594850346\n",
      "Round 170\n",
      "\tTraining metrics: OrderedDict([('loss', 0.014676664), ('num_examples', 3132), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0014133719960228\n",
      "Round 171\n",
      "\tTraining metrics: OrderedDict([('loss', 0.013447989), ('num_examples', 2940), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0012550480896607\n",
      "Round 172\n",
      "\tTraining metrics: OrderedDict([('loss', 0.012329208), ('num_examples', 3030), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0011137954425067\n",
      "Round 173\n",
      "\tTraining metrics: OrderedDict([('loss', 0.011334446), ('num_examples', 3146), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0009864241583273\n",
      "Round 174\n",
      "\tTraining metrics: OrderedDict([('loss', 0.010362181), ('num_examples', 3042), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0008730906411074\n",
      "Round 175\n",
      "\tTraining metrics: OrderedDict([('loss', 0.009154317), ('num_examples', 3138), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0007716749678366\n",
      "Round 176\n",
      "\tTraining metrics: OrderedDict([('loss', 0.008427416), ('num_examples', 3220), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0006801884155720\n",
      "Round 177\n",
      "\tTraining metrics: OrderedDict([('loss', 0.007204564), ('num_examples', 3102), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0005992121878080\n",
      "Round 178\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0068853176), ('num_examples', 3156), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0005267562228255\n",
      "Round 179\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0064314487), ('num_examples', 3194), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0004621205152944\n",
      "Round 180\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0056625684), ('num_examples', 3176), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0004045895475429\n",
      "Round 181\n",
      "\tTraining metrics: OrderedDict([('loss', 0.004867829), ('num_examples', 3028), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0003537728625815\n",
      "Round 182\n",
      "\tTraining metrics: OrderedDict([('loss', 0.004400598), ('num_examples', 3126), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0003085212665610\n",
      "Round 183\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0043082586), ('num_examples', 3120), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0002685492218006\n",
      "Round 184\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0037183943), ('num_examples', 3096), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0002336855395697\n",
      "Round 185\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0031314795), ('num_examples', 2992), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0002031056646956\n",
      "Round 186\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0029277264), ('num_examples', 3156), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0001761744351825\n",
      "Round 187\n",
      "\tTraining metrics: OrderedDict([('loss', 0.002667098), ('num_examples', 3154), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0001525139377918\n",
      "Round 188\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0024126833), ('num_examples', 2944), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0001319878501818\n",
      "Round 189\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0020833344), ('num_examples', 3028), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0001141747998190\n",
      "Round 190\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0018128022), ('num_examples', 3126), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000986226004898\n",
      "Round 191\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0016524543), ('num_examples', 3118), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000850705982884\n",
      "Round 192\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0014125812), ('num_examples', 2954), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000733435736038\n",
      "Round 193\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0012015287), ('num_examples', 3056), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000631378934486\n",
      "Round 194\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0011340552), ('num_examples', 3026), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000543246715097\n",
      "Round 195\n",
      "\tTraining metrics: OrderedDict([('loss', 0.001016386), ('num_examples', 3208), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000465958473796\n",
      "Round 196\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0008817849), ('num_examples', 3170), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000398849333578\n",
      "Round 197\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0008331628), ('num_examples', 3066), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000340903170581\n",
      "Round 198\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0007062656), ('num_examples', 3026), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000291271298920\n",
      "Round 199\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0006425492), ('num_examples', 3190), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000248339019890\n",
      "Round 200\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00054707733), ('num_examples', 3178), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000211254373426\n",
      "Round 201\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00043062732), ('num_examples', 2994), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000179680791916\n",
      "Round 202\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00044832364), ('num_examples', 3210), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000152492011694\n",
      "Round 203\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00034409997), ('num_examples', 3070), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000129252475745\n",
      "Round 204\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00031298638), ('num_examples', 3128), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000109327529572\n",
      "Round 205\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00026985083), ('num_examples', 3138), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000092367272373\n",
      "Round 206\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00023642344), ('num_examples', 3178), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000077801905718\n",
      "Round 207\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00020523899), ('num_examples', 3328), ('num_batches', 18)])\n",
      "\tValidation loss:  0.0000065313743107\n",
      "Round 208\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00021294701), ('num_examples', 2970), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000054909173741\n",
      "Round 209\n",
      "\tTraining metrics: OrderedDict([('loss', 0.0001507248), ('num_examples', 3220), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000046072736950\n",
      "Round 210\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00013219683), ('num_examples', 3214), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000038554881030\n",
      "Round 211\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00012260057), ('num_examples', 3080), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000032284117424\n",
      "Round 212\n",
      "\tTraining metrics: OrderedDict([('loss', 0.00012588897), ('num_examples', 3092), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000026978848382\n",
      "Round 213\n",
      "\tTraining metrics: OrderedDict([('loss', 9.245857e-05), ('num_examples', 3158), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000022501635613\n",
      "Round 214\n",
      "\tTraining metrics: OrderedDict([('loss', 8.361818e-05), ('num_examples', 3202), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000018738508061\n",
      "Round 215\n",
      "\tTraining metrics: OrderedDict([('loss', 6.937167e-05), ('num_examples', 2976), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000015619070837\n",
      "Round 216\n",
      "\tTraining metrics: OrderedDict([('loss', 5.9518392e-05), ('num_examples', 3046), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000013013318494\n",
      "Round 217\n",
      "\tTraining metrics: OrderedDict([('loss', 5.212517e-05), ('num_examples', 2986), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000010853086678\n",
      "Round 218\n",
      "\tTraining metrics: OrderedDict([('loss', 3.753352e-05), ('num_examples', 2974), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000009054562042\n",
      "Round 219\n",
      "\tTraining metrics: OrderedDict([('loss', 4.2480588e-05), ('num_examples', 3080), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000007546226470\n",
      "Round 220\n",
      "\tTraining metrics: OrderedDict([('loss', 3.1554853e-05), ('num_examples', 3122), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000006287103247\n",
      "Round 221\n",
      "\tTraining metrics: OrderedDict([('loss', 2.4296127e-05), ('num_examples', 2926), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000005251864081\n",
      "Round 222\n",
      "\tTraining metrics: OrderedDict([('loss', 2.6322383e-05), ('num_examples', 3128), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000004377551193\n",
      "Round 223\n",
      "\tTraining metrics: OrderedDict([('loss', 2.602987e-05), ('num_examples', 3200), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000003648522124\n",
      "Round 224\n",
      "\tTraining metrics: OrderedDict([('loss', 1.659308e-05), ('num_examples', 3134), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000003040562149\n",
      "Round 225\n",
      "\tTraining metrics: OrderedDict([('loss', 1.5759526e-05), ('num_examples', 3110), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000002533555516\n",
      "Round 226\n",
      "\tTraining metrics: OrderedDict([('loss', 1.2290847e-05), ('num_examples', 2990), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000002123777278\n",
      "Round 227\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0795594e-05), ('num_examples', 3060), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000001772857701\n",
      "Round 228\n",
      "\tTraining metrics: OrderedDict([('loss', 8.448926e-06), ('num_examples', 2992), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000001487875210\n",
      "Round 229\n",
      "\tTraining metrics: OrderedDict([('loss', 7.65748e-06), ('num_examples', 3144), ('num_batches', 18)])\n",
      "\tValidation loss:  0.0000001255418454\n",
      "Round 230\n",
      "\tTraining metrics: OrderedDict([('loss', 6.513553e-06), ('num_examples', 3058), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000001050528766\n",
      "Round 231\n",
      "\tTraining metrics: OrderedDict([('loss', 6.2196796e-06), ('num_examples', 3000), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000884754101\n",
      "Round 232\n",
      "\tTraining metrics: OrderedDict([('loss', 8.729958e-06), ('num_examples', 3066), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000741331121\n",
      "Round 233\n",
      "\tTraining metrics: OrderedDict([('loss', 5.1372344e-06), ('num_examples', 3208), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000632925463\n",
      "Round 234\n",
      "\tTraining metrics: OrderedDict([('loss', 4.791959e-06), ('num_examples', 3060), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000531970450\n",
      "Round 235\n",
      "\tTraining metrics: OrderedDict([('loss', 4.8972925e-06), ('num_examples', 3146), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000451504398\n",
      "Round 236\n",
      "\tTraining metrics: OrderedDict([('loss', 2.556526e-06), ('num_examples', 3114), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000383331837\n",
      "Round 237\n",
      "\tTraining metrics: OrderedDict([('loss', 3.9168995e-06), ('num_examples', 3130), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000324472360\n",
      "Round 238\n",
      "\tTraining metrics: OrderedDict([('loss', 3.5366627e-06), ('num_examples', 2844), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000279023897\n",
      "Round 239\n",
      "\tTraining metrics: OrderedDict([('loss', 2.392107e-06), ('num_examples', 3120), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000237300757\n",
      "Round 240\n",
      "\tTraining metrics: OrderedDict([('loss', 1.9345234e-06), ('num_examples', 3084), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000203773194\n",
      "Round 241\n",
      "\tTraining metrics: OrderedDict([('loss', 2.1299008e-06), ('num_examples', 3146), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000176206090\n",
      "Round 242\n",
      "\tTraining metrics: OrderedDict([('loss', 1.6220881e-06), ('num_examples', 3208), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000150501620\n",
      "Round 243\n",
      "\tTraining metrics: OrderedDict([('loss', 1.6285243e-06), ('num_examples', 3128), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000130757600\n",
      "Round 244\n",
      "\tTraining metrics: OrderedDict([('loss', 2.4243548e-06), ('num_examples', 3098), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000113248770\n",
      "Round 245\n",
      "\tTraining metrics: OrderedDict([('loss', 1.5312468e-06), ('num_examples', 2972), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000099092681\n",
      "Round 246\n",
      "\tTraining metrics: OrderedDict([('loss', 1.5584774e-06), ('num_examples', 3038), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000084936582\n",
      "Round 247\n",
      "\tTraining metrics: OrderedDict([('loss', 1.550932e-06), ('num_examples', 3098), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000074505779\n",
      "Round 248\n",
      "\tTraining metrics: OrderedDict([('loss', 1.5674466e-06), ('num_examples', 3166), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000067055197\n",
      "Round 249\n",
      "\tTraining metrics: OrderedDict([('loss', 1.3162171e-06), ('num_examples', 3068), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000059977157\n",
      "Round 250\n",
      "\tTraining metrics: OrderedDict([('loss', 1.0223458e-06), ('num_examples', 3100), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000050663931\n",
      "Round 251\n",
      "\tTraining metrics: OrderedDict([('loss', 9.5349264e-07), ('num_examples', 3286), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000047683701\n",
      "Round 252\n",
      "\tTraining metrics: OrderedDict([('loss', 9.0822084e-07), ('num_examples', 3160), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000042468296\n",
      "Round 253\n",
      "\tTraining metrics: OrderedDict([('loss', 8.0102035e-07), ('num_examples', 3100), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000039115537\n",
      "Round 254\n",
      "\tTraining metrics: OrderedDict([('loss', 8.175921e-07), ('num_examples', 3078), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000034272662\n",
      "Round 255\n",
      "\tTraining metrics: OrderedDict([('loss', 6.981483e-07), ('num_examples', 3056), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000030547376\n",
      "Round 256\n",
      "\tTraining metrics: OrderedDict([('loss', 5.847078e-07), ('num_examples', 3228), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000027194613\n",
      "Round 257\n",
      "\tTraining metrics: OrderedDict([('loss', 9.263835e-07), ('num_examples', 2970), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000023841853\n",
      "Round 258\n",
      "\tTraining metrics: OrderedDict([('loss', 7.335033e-07), ('num_examples', 3146), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000021979210\n",
      "Round 259\n",
      "\tTraining metrics: OrderedDict([('loss', 9.3089506e-07), ('num_examples', 3198), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000020116564\n",
      "Round 260\n",
      "\tTraining metrics: OrderedDict([('loss', 7.667596e-07), ('num_examples', 3056), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000020116564\n",
      "Round 261\n",
      "\tTraining metrics: OrderedDict([('loss', 8.8419057e-07), ('num_examples', 3100), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000017508861\n",
      "Round 262\n",
      "\tTraining metrics: OrderedDict([('loss', 4.9480377e-07), ('num_examples', 3052), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000016763804\n",
      "Round 263\n",
      "\tTraining metrics: OrderedDict([('loss', 6.351067e-07), ('num_examples', 3048), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000015273688\n",
      "Round 264\n",
      "\tTraining metrics: OrderedDict([('loss', 6.7274055e-07), ('num_examples', 3080), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000013783571\n",
      "Round 265\n",
      "\tTraining metrics: OrderedDict([('loss', 7.697708e-07), ('num_examples', 3032), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000013038515\n",
      "Round 266\n",
      "\tTraining metrics: OrderedDict([('loss', 5.453414e-07), ('num_examples', 3038), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000012293456\n",
      "Round 267\n",
      "\tTraining metrics: OrderedDict([('loss', 5.8803124e-07), ('num_examples', 3052), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000012293456\n",
      "Round 268\n",
      "\tTraining metrics: OrderedDict([('loss', 5.451039e-07), ('num_examples', 2984), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000011548399\n",
      "Round 269\n",
      "\tTraining metrics: OrderedDict([('loss', 4.8435425e-07), ('num_examples', 3092), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000011175869\n",
      "Round 270\n",
      "\tTraining metrics: OrderedDict([('loss', 6.119922e-07), ('num_examples', 3190), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000009685753\n",
      "Round 271\n",
      "\tTraining metrics: OrderedDict([('loss', 4.4496062e-07), ('num_examples', 3104), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000009313225\n",
      "Round 272\n",
      "\tTraining metrics: OrderedDict([('loss', 6.707916e-07), ('num_examples', 3170), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000007823109\n",
      "Round 273\n",
      "\tTraining metrics: OrderedDict([('loss', 4.935709e-07), ('num_examples', 3212), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000007450580\n",
      "Round 274\n",
      "\tTraining metrics: OrderedDict([('loss', 4.1607416e-07), ('num_examples', 3088), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000006705522\n",
      "Round 275\n",
      "\tTraining metrics: OrderedDict([('loss', 4.0645492e-07), ('num_examples', 3086), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000006705522\n",
      "Round 276\n",
      "\tTraining metrics: OrderedDict([('loss', 5.043883e-07), ('num_examples', 3024), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000005960464\n",
      "Round 277\n",
      "\tTraining metrics: OrderedDict([('loss', 5.719778e-07), ('num_examples', 3260), ('num_batches', 18)])\n",
      "\tValidation loss:  0.0000000005587935\n",
      "Round 278\n",
      "\tTraining metrics: OrderedDict([('loss', 5.252788e-07), ('num_examples', 3002), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000005215406\n",
      "Round 279\n",
      "\tTraining metrics: OrderedDict([('loss', 5.028938e-07), ('num_examples', 3138), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000005215406\n",
      "Round 280\n",
      "\tTraining metrics: OrderedDict([('loss', 5.470856e-07), ('num_examples', 3190), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000004842877\n",
      "Round 281\n",
      "\tTraining metrics: OrderedDict([('loss', 4.0150388e-07), ('num_examples', 3206), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000004842877\n",
      "Round 282\n",
      "\tTraining metrics: OrderedDict([('loss', 3.913104e-07), ('num_examples', 2980), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000004842877\n",
      "Round 283\n",
      "\tTraining metrics: OrderedDict([('loss', 4.297455e-07), ('num_examples', 3058), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000004842877\n",
      "Round 284\n",
      "\tTraining metrics: OrderedDict([('loss', 5.2440294e-07), ('num_examples', 2972), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000004470348\n",
      "Round 285\n",
      "\tTraining metrics: OrderedDict([('loss', 5.648715e-07), ('num_examples', 3144), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000004470348\n",
      "Round 286\n",
      "\tTraining metrics: OrderedDict([('loss', 4.6026494e-07), ('num_examples', 3108), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000004097819\n",
      "Round 287\n",
      "\tTraining metrics: OrderedDict([('loss', 3.9268932e-07), ('num_examples', 3196), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000004097819\n",
      "Round 288\n",
      "\tTraining metrics: OrderedDict([('loss', 4.5079125e-07), ('num_examples', 3108), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000004097819\n",
      "Round 289\n",
      "\tTraining metrics: OrderedDict([('loss', 3.9539782e-07), ('num_examples', 3112), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000004097819\n",
      "Round 290\n",
      "\tTraining metrics: OrderedDict([('loss', 4.3669465e-07), ('num_examples', 3148), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000003725290\n",
      "Round 291\n",
      "\tTraining metrics: OrderedDict([('loss', 4.7675732e-07), ('num_examples', 3080), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000003725290\n",
      "Round 292\n",
      "\tTraining metrics: OrderedDict([('loss', 3.9370224e-07), ('num_examples', 3060), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000003725290\n",
      "Round 293\n",
      "\tTraining metrics: OrderedDict([('loss', 4.5124133e-07), ('num_examples', 3130), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000003725290\n",
      "Round 294\n",
      "\tTraining metrics: OrderedDict([('loss', 5.4002004e-07), ('num_examples', 3060), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000003725290\n",
      "Round 295\n",
      "\tTraining metrics: OrderedDict([('loss', 4.96896e-07), ('num_examples', 3066), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000003725290\n",
      "Round 296\n",
      "\tTraining metrics: OrderedDict([('loss', 4.460492e-07), ('num_examples', 3090), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000003725290\n",
      "Round 297\n",
      "\tTraining metrics: OrderedDict([('loss', 5.5038225e-07), ('num_examples', 3026), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000003725290\n",
      "Round 298\n",
      "\tTraining metrics: OrderedDict([('loss', 5.166179e-07), ('num_examples', 3236), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 299\n",
      "\tTraining metrics: OrderedDict([('loss', 4.5927095e-07), ('num_examples', 2932), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 300\n",
      "\tTraining metrics: OrderedDict([('loss', 4.3447642e-07), ('num_examples', 3000), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 301\n",
      "\tTraining metrics: OrderedDict([('loss', 4.6901107e-07), ('num_examples', 3200), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 302\n",
      "\tTraining metrics: OrderedDict([('loss', 4.338728e-07), ('num_examples', 3116), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 303\n",
      "\tTraining metrics: OrderedDict([('loss', 4.3057102e-07), ('num_examples', 3226), ('num_batches', 18)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 304\n",
      "\tTraining metrics: OrderedDict([('loss', 3.9284689e-07), ('num_examples', 3026), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 305\n",
      "\tTraining metrics: OrderedDict([('loss', 5.1622146e-07), ('num_examples', 3196), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 306\n",
      "\tTraining metrics: OrderedDict([('loss', 4.698244e-07), ('num_examples', 3112), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000003352761\n",
      "Round 307\n",
      "\tTraining metrics: OrderedDict([('loss', 4.6246294e-07), ('num_examples', 3152), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000002980232\n",
      "Round 308\n",
      "\tTraining metrics: OrderedDict([('loss', 4.2639243e-07), ('num_examples', 3162), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000002980232\n",
      "Round 309\n",
      "\tTraining metrics: OrderedDict([('loss', 4.2396627e-07), ('num_examples', 3186), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000002980232\n",
      "Round 310\n",
      "\tTraining metrics: OrderedDict([('loss', 3.8052065e-07), ('num_examples', 2864), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000002235174\n",
      "Round 311\n",
      "\tTraining metrics: OrderedDict([('loss', 4.912157e-07), ('num_examples', 3100), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 312\n",
      "\tTraining metrics: OrderedDict([('loss', 4.98439e-07), ('num_examples', 3134), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 313\n",
      "\tTraining metrics: OrderedDict([('loss', 4.266682e-07), ('num_examples', 3196), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 314\n",
      "\tTraining metrics: OrderedDict([('loss', 3.860412e-07), ('num_examples', 3004), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 315\n",
      "\tTraining metrics: OrderedDict([('loss', 3.7486853e-07), ('num_examples', 3070), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 316\n",
      "\tTraining metrics: OrderedDict([('loss', 3.8134527e-07), ('num_examples', 3066), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 317\n",
      "\tTraining metrics: OrderedDict([('loss', 3.8237954e-07), ('num_examples', 3092), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 318\n",
      "\tTraining metrics: OrderedDict([('loss', 4.5344692e-07), ('num_examples', 3048), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 319\n",
      "\tTraining metrics: OrderedDict([('loss', 4.056964e-07), ('num_examples', 3090), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 320\n",
      "\tTraining metrics: OrderedDict([('loss', 4.0909666e-07), ('num_examples', 3092), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001862645\n",
      "Round 321\n",
      "\tTraining metrics: OrderedDict([('loss', 4.426262e-07), ('num_examples', 3192), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 322\n",
      "\tTraining metrics: OrderedDict([('loss', 4.787339e-07), ('num_examples', 3138), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 323\n",
      "\tTraining metrics: OrderedDict([('loss', 4.759205e-07), ('num_examples', 3130), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 324\n",
      "\tTraining metrics: OrderedDict([('loss', 3.760712e-07), ('num_examples', 3012), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 325\n",
      "\tTraining metrics: OrderedDict([('loss', 4.08198e-07), ('num_examples', 2824), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 326\n",
      "\tTraining metrics: OrderedDict([('loss', 4.109931e-07), ('num_examples', 3172), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 327\n",
      "\tTraining metrics: OrderedDict([('loss', 3.820234e-07), ('num_examples', 3186), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 328\n",
      "\tTraining metrics: OrderedDict([('loss', 5.1461205e-07), ('num_examples', 2922), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 329\n",
      "\tTraining metrics: OrderedDict([('loss', 4.0509363e-07), ('num_examples', 3074), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 330\n",
      "\tTraining metrics: OrderedDict([('loss', 4.036717e-07), ('num_examples', 3200), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 331\n",
      "\tTraining metrics: OrderedDict([('loss', 4.0868255e-07), ('num_examples', 2984), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 332\n",
      "\tTraining metrics: OrderedDict([('loss', 4.7229946e-07), ('num_examples', 3154), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 333\n",
      "\tTraining metrics: OrderedDict([('loss', 4.037028e-07), ('num_examples', 3084), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 334\n",
      "\tTraining metrics: OrderedDict([('loss', 3.7580566e-07), ('num_examples', 3056), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 335\n",
      "\tTraining metrics: OrderedDict([('loss', 3.9775549e-07), ('num_examples', 3042), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 336\n",
      "\tTraining metrics: OrderedDict([('loss', 4.009412e-07), ('num_examples', 3110), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 337\n",
      "\tTraining metrics: OrderedDict([('loss', 3.791083e-07), ('num_examples', 3130), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 338\n",
      "\tTraining metrics: OrderedDict([('loss', 4.0989923e-07), ('num_examples', 3284), ('num_batches', 17)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 339\n",
      "\tTraining metrics: OrderedDict([('loss', 4.0051958e-07), ('num_examples', 3110), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 340\n",
      "\tTraining metrics: OrderedDict([('loss', 4.2907502e-07), ('num_examples', 3090), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 341\n",
      "\tTraining metrics: OrderedDict([('loss', 3.7229213e-07), ('num_examples', 2894), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 342\n",
      "\tTraining metrics: OrderedDict([('loss', 3.6664366e-07), ('num_examples', 3094), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 343\n",
      "\tTraining metrics: OrderedDict([('loss', 4.3543622e-07), ('num_examples', 3058), ('num_batches', 16)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 344\n",
      "\tTraining metrics: OrderedDict([('loss', 3.8015554e-07), ('num_examples', 3048), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 345\n",
      "\tTraining metrics: OrderedDict([('loss', 3.9941364e-07), ('num_examples', 2830), ('num_batches', 13)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 346\n",
      "\tTraining metrics: OrderedDict([('loss', 4.037676e-07), ('num_examples', 2966), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 347\n",
      "\tTraining metrics: OrderedDict([('loss', 3.9817093e-07), ('num_examples', 3052), ('num_batches', 14)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 348\n",
      "\tTraining metrics: OrderedDict([('loss', 3.8328542e-07), ('num_examples', 3020), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n",
      "Round 349\n",
      "\tTraining metrics: OrderedDict([('loss', 4.3850133e-07), ('num_examples', 2948), ('num_batches', 15)])\n",
      "\tValidation loss:  0.0000000001117587\n"
     ]
    }
   ],
   "source": [
    "#if len(argv) > 1:\n",
    "#  raise app.UsageError('Too many command-line arguments.')\n",
    "# If GPU is provided, TFF will by default use the first GPU like TF. The\n",
    "# following lines will configure TFF to use multi-GPUs and distribute client\n",
    "# computation on the GPUs. Note that we put server computatoin on CPU to avoid\n",
    "# potential out of memory issue when a large number of clients is sampled per\n",
    "# round. The client devices below can be an empty list when no GPU could be\n",
    "# detected by TF.\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "client_devices = tf.config.list_logical_devices('GPU')\n",
    "server_device = tf.config.list_logical_devices('CPU')[0]\n",
    "tff.backends.native.set_local_python_execution_context(\n",
    "    server_tf_device=server_device, client_tf_devices=client_devices)\n",
    "train_data, test_data = get_custom_dataset()\n",
    "def tff_model_fn():\n",
    "  \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "  keras_model = create_fedavg_model(only_digits=True)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "  #metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      loss=loss,\n",
    "      #metrics=metrics,\n",
    "      input_spec=train_data.element_type_structure)\n",
    "\n",
    "iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "    tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "server_state = iterative_process.initialize()\n",
    "# Keras model that represents the global model we'll evaluate test data on.\n",
    "keras_model = create_fedavg_model(only_digits=True)\n",
    "for round_num in range(TOTAL_ROUNDS):\n",
    "  sampled_clients = np.random.choice(\n",
    "      train_data.client_ids,\n",
    "      size=TRAIN_CLIENTS_PER_ROUND,\n",
    "      replace=False)\n",
    "  sampled_train_data = [\n",
    "      train_data.create_tf_dataset_for_client(client)\n",
    "      for client in sampled_clients\n",
    "  ]\n",
    "  server_state, train_metrics = iterative_process.next(\n",
    "      server_state, sampled_train_data)\n",
    "  print(f'Round {round_num}')\n",
    "  print(f'\\tTraining metrics: {train_metrics}')\n",
    "  train_loss_list.append(train_metrics.get('loss'))\n",
    "\n",
    "  if round_num % ROUNDS_PER_EVAL == 0:\n",
    "    server_state.model.assign_weights_to(keras_model)\n",
    "    val_loss = evaluate(keras_model, test_data)\n",
    "    val_loss_list.append(val_loss)\n",
    "    print(f'\\tValidation loss: {val_loss: .16f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7fb0070b80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list, label=\"Training Loss\")\n",
    "plt.plot(val_loss_list, label=\"Validation Loss\")\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_features = normal_test_data.copy()\n",
    "normal_test_features.pop('label')\n",
    "tensor_normal_test_features = tf.convert_to_tensor(normal_test_features, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruct_normal = keras_model(tensor_normal_test_features)\n",
    "normal_test_loss = tf.keras.losses.mae(y_true=normal_test_features, y_pred=reconstruct_normal)\n",
    "plt.hist(normal_test_loss[None,:], bins=300)\n",
    "plt.xlabel(\"Test normal loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomal_test_features = anomalous_test_data.copy()\n",
    "anomal_test_features.pop('label')\n",
    "tensor_anomal_test_features = tf.convert_to_tensor(anomal_test_features, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXAklEQVR4nO3deZhsdX3n8fcHLgYRBJUeHlTwEoIyxOWK9zG4jIKiD0qiJoMmjBDIkJBx1Bi3Cc44EyN5noBrxmU018gyDnELGBEclSEXJO6XRdY4KkIGRGkNKmrC+p0/zunYNr2c7tunqrrP+/U89XTVqbN877nVnz516lu/k6pCkjQcO4y7AEnSaBn8kjQwBr8kDYzBL0kDY/BL0sBsGHcBXey55561cePGcZchSWvKpZde+r2qmpo7fU0E/8aNG9m2bdu4y5CkNSXJjfNN91SPJA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL62ijSedP5JlpO1h8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/Bqs7emmsRNHa5nBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2Pwa12x20ZamsEvSQNj8EvSwPQW/El2TvLlJF9Nck2SP2mn75fkS0m+keTDSe7XVw2SpPvq84j/DuAZVfU4YBNwRJJDgFOBt1fVLwG3ASf0WIMkaY7egr8aP24f7tTeCngG8Nft9DOBF/RVgyTpvno9x59kxyRXALcCFwDfBH5QVXe3s9wEPKzPGiRJP6/X4K+qe6pqE/Bw4InAgV2XTXJikm1Jtk1PT/dVoiaQLZlSv0bS1VNVPwC2Ak8C9kiyoX3q4cDNCyyzpao2V9XmqampUZQpSYPQZ1fPVJI92vv3B54FXEfzB+CodrbjgI/3VYMk6b42LD3Liu0NnJlkR5o/MB+pqvOSXAt8KMmfApcD7++xBknSHL0Ff1VdCTx+nunX05zvlySNgd/claSBMfi1LizWCdS1S2ip+ew20nph8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/FqX5nbgrKQjZxxdPDPbtINIfTL4JWlgDH5JGhiDX5IGxuCXpIEx+CVpYAx+jcSkdqksVNdy613pWEGj3C+T+n+g0TP4JWlgDH5JGhiDX5IGxuCXpIEx+CVpYAx+SRoYg1+9W04bYZd5J60tsWvNa2WgOK1/Br8kDYzBL0kD01vwJ9knydYk1ya5Jskr2ulvSHJzkiva23P7qkGSdF8belz33cCrq+qyJLsBlya5oH3u7VX1lh63LUlaQG/BX1W3ALe0929Pch3wsL62J0nqZiTn+JNsBB4PfKmd9LIkVyY5LcmDFljmxCTbkmybnp4eRZkakO3plumr08YOHo1K78GfZFfgbOAPq+pHwHuA/YFNNO8I3jrfclW1pao2V9XmqampvsuUpMHoNfiT7EQT+mdV1TkAVfXdqrqnqu4F3gc8sc8aJEk/r8+ungDvB66rqrfNmr73rNl+Hbi6rxokSffVZ1fPU4BjgauSXNFO+8/A0Uk2AQXcAPx+jzVIkubos6vn74DM89Qn+9qmJGlpfnNXvZnEzpmVWu165q7PSzBqlAx+SRoYg1+SBsbgl6SBMfglaWAMfkkamCWDP8mbkjwwyU5JLkwyneSYURSn9We9da+Mo0NmpVfzWmx9GpYuR/zPbsfY+VWaL1z9EvDaPouSJPWnS/DPfMnrSOCjVfXDHuuRJPWsyzd3z0vy98A/AS9JMgX8c79lSZL6suQRf1WdBDwZ2FxVdwE/BZ7fd2GSpH50+XB3F+A/0oyjD/BQYHOfRUmS+tPlHP/pwJ00R/0ANwN/2ltFkqRedQn+/avqTcBdAFX1U+YfdVPqbFQthF22M7s9su+6VrMVc1xtmLZ/rn1dgv/OJPenGT+fJPsDd/RalSSpN126ev4Y+BSwT5KzaC6wcnyfRUmS+rNk8FfVBUkuAw6hOcXziqr6Xu+VSZJ6sWDwJzl4zqRb2p/7Jtm3qi7rryxJUl8WO+J/6yLPFfCMVa5FkjQCC364W1WHLXIz9AWsXofHUutZ7PmuNaz2fKNel7RaljzHn2Rnmi9wPZXmSP8S4L1V5bANkrQGdenq+Z/A7cA728f/DvgA8MK+ipIk9adL8D+6qg6a9XhrkmuXWijJPjR/NPaieaewpar+e5IHAx8GNtIM8/yiqrptuYVLklamyxe4LktyyMyDJL8CbOuw3N3Aq9s/GocAL01yEHAScGFVHQBc2D6WJI1IlyP+JwCfT/IP7eN9ga8luQqoqnrsfAtV1S20LaBVdXuS64CH0YzseWg725nARcAfrfQfIElani5H/EcA+wFPb2/7tdN+Ffi1LhtJshF4PPAlYK/2jwLAd2hOBc23zIlJtiXZNj093WUzWoOW2/Uy7i6Z2dtfqJZxj8Uz7n2kyddlPP4bgR8BuwMPmblV1Y3tc4tKsitwNvCH7SUcZ6+7aMcAmme7W6pqc1VtnpqaWvpfIknqpEs758k0Y/N8k5+FdKcvcCXZiSb0z6qqc9rJ302yd1XdkmRv4NaVFC5JWpku5/hfRDM0853LWXGSAO8Hrquqt8166lzgOOCU9ufHl7NeSdL26XKO/2pgjxWs+ynAscAzklzR3p5LE/jPSvJ14PD2sSRpRLoc8f8ZcHmSq5k1Dn9VPW+xharq71j4gi3P7FyhJGlVdQn+M4FTgauAe/stR5LUty6nen5aVe+oqq1VdfHMrffKpEWM8tKNK9lW10s+Lndd2zOY3XK2qfWtyxH/JUn+jOZD2dmnehyPX5LWoC7B//j25yGzpjkevyStUV0uvXjYKAqRJI1GlyN+khwJ/DKw88y0qnpjX0VJkvqz5Ie7Sd4L/Cbwcpr2zBcCj+i5LklST7p09Ty5qn4buK2q/gR4EvDIfsvSKE1Kp8d660gZ9SUcl3N5yuWubyXLa3J1Cf5/an/+NMlDgbuAvfsrSZLUpy7n+M9LsgfwZuAymo6ev+yzKElSf7p09Zzc3j07yXnAzlX1w37LkiT1pcuHuycn2QBQVXcAleT03iuTJPWiyzn+DcCXkjw2ybOArwCX9luWJKkvXa7A9TrgP9FcNvFM4MiqelffhWkyLKf7Y9SXUez70odrwVL7fjn7Ykj7bei6nOp5GvAO4I00F0Z/Z9vdI0lag7p09bwFeGFVXQuQ5DeAvwUO7LMwSVI/ugT/k6rqnpkHVXVOEodllqQ1qsuHu/snubC9AhdJHgu8pN+yJEl96RL87wNeR/ONXarqSuC3+ixKktSfLsG/S1V9ec60u/soRpqtry6TtbbeUa1/e016ffqZLsH/vST70wzVQJKjgFt6rUqS1JsuH+6+FNgCHJjkZuBbwIt7rUqS1JsuY/VcDxye5AHADlV1e/9lSZL60uVUDwBV9ZPlhH6S05LcOtMN1E57Q5Kbk1zR3p673IIlSdunc/CvwBnAEfNMf3tVbWpvn+xx+5KkeSwY/Ele2P7cbyUrrqrPAv+4wrokST1Z7Ij/de3Ps1d5my9LcmV7KuhBC82U5MQk25Jsm56eXuUStBxzBwJbadueg6pNLv8PhmWx4P9+ks8A+yU5d+5thdt7D7A/sImmJfStC81YVVuqanNVbZ6amlrh5iRJcy3W1XMkcDDwARYJ6OWoqu/O3E/yPuC81VivJKm7BYO/qu4EvpjkyVU1nWTXdvqPV7qxJHtX1cyXv34duHqx+SVJq6/LF7j2ak/5PBhIkmnguKpaNLSTfBA4FNgzyU3AHwOHJtlE8y3gG4DfX3npkqSV6BL8W4BXVdVWgCSHttOevNhCVXX0PJPfv8z6JEmrrEsf/wNmQh+gqi4CHtBbRVr3VrODZNSXe1wrlnPJzFFsS5OlyxH/9Un+K82HvADHANf3V5IkqU9djvj/PTAFnEPT079nO02StAZ1GaTtNuAPRlCLJGkE+hyrR5I0gQx+SRoYg1/3YZfG+tBlbKXV7oqa/byvo8m1ZPAneXiSjyWZbsfXPzvJw0dRnCRp9XU54j8dOBfYG3go8Il2miRpDeoS/FNVdXpV3d3ezqBp75QkrUFdgv/7SY5JsmN7Owb4ft+FSZL60fULXC8CvkMzhv5RwO/0WZQkqT9dvsB1I/C8EdSinm086XxuOOXIzvOuZF2r3clhZ8j4be+V1zR5Fgz+JP9tkeWqqk7uoR5JUs8WO+L/yTzTHgCcADwEMPglaQ1a7Apc/3K5xSS7Aa+gObf/IVbpUoySpNFb9Bx/kgcDrwJeDJwJHNwO2iZJWqMWO8f/ZuA3aK629ZjtudauJGlyLNbO+Wqab+q+Hvh2kh+1t9uT/Gg05UmSVtuCwV9VO1TV/atqt6p64KzbblX1wFEWqe3XRyveKC/v18V6aTcc979jOdu31XNtcnROSRoYg1+SBqa34E9yWjuM89Wzpj04yQVJvt7+fFBf25ckza/PI/4zgCPmTDsJuLCqDgAubB9Lkkaot+Cvqs8C/zhn8vNpvg9A+/MFfW1fkjS/UZ/j36uqbmnvfwfYa6EZk5yYZFuSbdPT06OpbiDm68CwK2PtmrT/u9W81KP6MbYPd6uqgFrk+S1VtbmqNk9Ned0XSVotow7+7ybZG6D9eeuIty9Jgzfq4D8XOK69fxzw8RFvX5IGr892zg8CXwAeleSmJCcApwDPSvJ14PD2sSRphJa8AtdKVdXRCzz1zL62KUlamt/cnUCT2PkwiTVpbVjotbNarylfm8tn8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAb/GrTxpPPv08I27pa2cW9f/VjN/1cv1Tk5DH5JGhiDX5IGxuCXpIEx+CVpYAx+SRoYg3+NWK3L2XlZPHUx7g6c2eve3u34ur4vg1+SBsbgl6SBMfglaWAMfkkaGINfkgbG4F9F4+gemNv9MF83xHx1LfZc1+1p/RnV/+/s19/s20I1LFWXr8vlMfglaWAMfkkamA3j2GiSG4DbgXuAu6tq8zjqkKQhGkvwtw6rqu+NcfuSNEie6pGkgRnXEX8Bn0lSwF9U1Za5MyQ5ETgRYN999x1xeaMxuxPhhlOO7G3do1hOms3X0WQb1xH/U6vqYOA5wEuTPG3uDFW1pao2V9Xmqamp0VcoSevUWIK/qm5uf94KfAx44jjqkKQhGnnwJ3lAkt1m7gPPBq4edR2SNFTjOMe/F/CxJDPb/6uq+tQY6pCkQRp58FfV9cDjRr1dSVLDdk5JGhiDv4M+WtMWWudqD0blpRY1RCv9/RoKg1+SBsbgl6SBMfglaWAMfkkaGINfkgZm3Qd/10/xt/dShF27COZeHnE5617uctK4reQyikstu9zfufmmdalhtTrsJvH3cd0HvyTp5xn8kjQwBr8kDYzBL0kDY/BL0sAMNvi3p9tgpdtbzvq7dPJMYreANJ++Xquz17u921hsXUt1E8237CT/fg42+CVpqAx+SRoYg1+SBsbgl6SBMfglaWAMfkkamEEF/3IGTFuoJWtmmYXau5bbtrm9y0nr2UItll0GaFvJQGwr/d3ta/6+MmFQwS9JMvglaXDGEvxJjkjytSTfSHLSOGqQpKEaefAn2RF4N/Ac4CDg6CQHjboOSRqqcRzxPxH4RlVdX1V3Ah8Cnj+GOiRpkFJVo91gchRwRFX9bvv4WOBXquplc+Y7ETixffgo4GsjLXQ09gS+N+4iJpj7Z3Hun4W5bxqPqKqpuRM3jKOSLqpqC7Bl3HX0Kcm2qto87jomlftnce6fhblvFjeOUz03A/vMevzwdpokaQTGEfxfAQ5Isl+S+wG/BZw7hjokaZBGfqqnqu5O8jLg08COwGlVdc2o65gQ6/pU1ipw/yzO/bMw980iRv7hriRpvPzmriQNjMEvSQNj8I/AUkNUJHlVkmuTXJnkwiSPGEed49J1CI8k/zZJJRlMm16XfZPkRe3r55okfzXqGsepw+/Wvkm2Jrm8/f167jjqnDhV5a3HG80H2N8EfhG4H/BV4KA58xwG7NLefwnw4XHXPUn7p51vN+CzwBeBzeOue1L2DXAAcDnwoPbxvxp33RO2f7YAL2nvHwTcMO66J+HmEX//lhyioqq2VtVP24dfpPluw1B0HcLjZOBU4J9HWdyYddk3vwe8u6puA6iqW0dc4zh12T8FPLC9vzvw7RHWN7EM/v49DPh/sx7f1E5byAnA/+61osmy5P5JcjCwT1UN7Uo1XV47jwQemeRzSb6Y5IiRVTd+XfbPG4BjktwEfBJ4+WhKm2wTO2TDECU5BtgMPH3ctUyKJDsAbwOOH3Mpk2oDzemeQ2neKX42yWOq6gfjLGqCHA2cUVVvTfIk4ANJHl1V9467sHHyiL9/nYaoSHI48F+A51XVHSOqbRIstX92Ax4NXJTkBuAQ4NyBfMDb5bVzE3BuVd1VVd8C/i/NH4Ih6LJ/TgA+AlBVXwB2phnAbdAM/v4tOURFkscDf0ET+kM6RwtL7J+q+mFV7VlVG6tqI81nIM+rqm3jKXekugxv8jc0R/sk2ZPm1M/1I6xxnLrsn38AngmQ5F/TBP/0SKucQAZ/z6rqbmBmiIrrgI9U1TVJ3pjkee1sbwZ2BT6a5Iokgxm7qOP+GaSO++bTwPeTXAtsBV5bVd8fT8Wj1XH/vBr4vSRfBT4IHF9ti8+QOWSDJA2MR/ySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr/GIslD2tbVK5J8J8nNsx7fr8PyhyZ58ihqXakkG5Nc3eP635DkNX2tX+uXQzZoLNpe803QBBjw46p6yzJWcSjwY+Dzq12btN55xK+JkeQJSS5OcmmSTyfZu53+B7OuV/ChJBuB/wC8sn2H8G/mrOeJSb7QjsH++SSPaqcfn+ScJJ9K8vUkb5q1zNFJrkpydZJTZ03/cZI3t2Pd/5923RcluX7mS0Ltkf0lSS5rb/d5J5Jk5ySnt9u4PMlhs2p616z5zmvfzeyY5Iy2nquSvHKJfbepHaTtyiQfS/Kg+fZdO+3ps95dXZ5kt2X+V2mtG/e40N680Yyg+Fqao/epdtpvAqe1978N/EJ7f49Zy7xmgfU9ENjQ3j8cOLu9fzzNcAa703x1/0aasV4eSvPV/imad8F/C7ygXaaA57T3PwZ8BtgJeBxwRTt9F2Dn9v4BwLb2/kbg6vb+q2f9ew5st7dzW9O7ZtV+Hs27mScAF8yavscC++017f0rgae3998I/Pki++4TwFPa+7vO7Ctvw7l5qkeT4hdoBmO7IAk0F9m4pX3uSuCsJH9DMzbNUnYHzkxyAE1w7zTruQur6ocA7TAHjwAeAlxUVdPt9LOAp7XbuhP4VLvsVcAdVXVXkqtogp12/e9Ksgm4h2a8nLmeCrwToKr+PsmNC8w343rgF5O8Ezif5g/OvJLsThPqF7eTzgQ+2t6fb999Dnhb++88p6puWqQOrUOe6tGkCHBNVW1qb4+pqme3zx0JvBs4GPhKkqUOWE4GtlbVo4FfozmynjF75NN7WPpzrruqamZck3tnlq9mWN+ZZV8JfJfmXcBmmqtBdXU3P/97uHO7/tva9V1Ec1rrL5exztnus++q6hTgd4H7A59LcuAK1601yuDXpLgDmEozZjpJdkryy2nG49+nqrYCf0RzNL8rcDvNkM3z2Z2fDc97fIdtfxl4epI9k+xIM4b7xUssM3d7t7R/DI6lebcy1yXAiwGSPBLYF/gacAOwKckOSfahuarUzEibO1TV2cDraYJ7Xu07mNtmfdZxLHDxQvsuyf5VdVVVnUozwqXBPzCe6tGkuBc4CnhHe+piA/DnNOPL/692WoB3VNUPknwC+OskzwdeXlWXzFrXm2hO9bye5jTJoqrqljQX6t7abuP8qvr4Mmr/H8DZSX6b5rTQTxaY5z3tKaK7aUaJvCPJ54BvAdfSjDB5WTv/w4DT2/AGeN0SNRwHvDfJLjSniX6H5g/QfPvu5PbD5XuBaxjWFd+Eo3NK0uB4qkeSBsbgl6SBMfglaWAMfkkaGINfkgbG4JekgTH4JWlg/j8c59grZLQC5wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruct_anomal = keras_model(tensor_anomal_test_features)\n",
    "anomal_test_loss = tf.keras.losses.mae(y_true=anomal_test_features, y_pred=reconstruct_anomal)\n",
    "plt.hist(anomal_test_loss[None,:], bins=300)\n",
    "plt.xlabel(\"Test anomalous loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a value a std greater from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.64920574\n"
     ]
    }
   ],
   "source": [
    "threshold = np.mean(normal_test_loss) + np.std(normal_test_loss)\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify instance as abnormal if the reconstruction error is greater than the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data, threshold):\n",
    "  reconstructions = model(data)\n",
    "  loss = tf.keras.losses.mean_squared_error(reconstructions, data)\n",
    "  return tf.math.less(loss, threshold)\n",
    "\n",
    "def print_stats(predictions, labels):\n",
    "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
    "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
    "  print(\"Recall = {}\".format(recall_score(labels, predictions))) #sensitivity\n",
    "  print(\"F1 = {}\".format(f1_score(labels, predictions)))\n",
    "  print(\"ROC_AUC = {}\".format(roc_auc_score(labels, predictions)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5047338196492317\n",
      "Precision = 0.5041374920432845\n",
      "Recall = 0.9768732654949122\n",
      "F1 = 0.665057205836045\n",
      "ROC_AUC = 0.5015616327474561\n"
     ]
    }
   ],
   "source": [
    "# Results dont make sense give more weight to anomaly class in the learning process\n",
    "mix_test = test.copy()\n",
    "mix_labels = mix_test.pop('label')\n",
    "preds = predict(keras_model, np.array(mix_test), threshold)\n",
    "print_stats(preds, mix_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "  if len(argv) > 1:\n",
    "    raise app.UsageError('Too many command-line arguments.')\n",
    "  # If GPU is provided, TFF will by default use the first GPU like TF. The\n",
    "  # following lines will configure TFF to use multi-GPUs and distribute client\n",
    "  # computation on the GPUs. Note that we put server computatoin on CPU to avoid\n",
    "  # potential out of memory issue when a large number of clients is sampled per\n",
    "  # round. The client devices below can be an empty list when no GPU could be\n",
    "  # detected by TF.\n",
    "  client_devices = tf.config.list_logical_devices('GPU')\n",
    "  server_device = tf.config.list_logical_devices('CPU')[0]\n",
    "  tff.backends.native.set_local_python_execution_context(\n",
    "      server_tf_device=server_device, client_tf_devices=client_devices)\n",
    "  train_data, test_data = get_custom_dataset()\n",
    "\n",
    "  def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "    keras_model = create_fedavg_model(only_digits=True)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        input_spec=train_data.element_type_structure)\n",
    "\n",
    "  iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "      tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "  server_state = iterative_process.initialize()\n",
    "  # Keras model that represents the global model we'll evaluate test data on.\n",
    "  keras_model = create_fedavg_model(only_digits=True)\n",
    "  for round_num in range(TOTAL_ROUNDS):\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_data.client_ids,\n",
    "        size=TRAIN_CLIENTS_PER_ROUND,\n",
    "        replace=False)\n",
    "    sampled_train_data = [\n",
    "        train_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "    server_state, train_metrics = iterative_process.next(\n",
    "        server_state, sampled_train_data)\n",
    "    print(f'Round {round_num}')\n",
    "    print(f'\\tTraining metrics: {train_metrics}')\n",
    "    if round_num % ROUNDS_PER_EVAL == 0:\n",
    "      server_state.model.assign_weights_to(keras_model)\n",
    "      accuracy = evaluate(keras_model, test_data)\n",
    "      print(f'\\tValidation accuracy: {accuracy * 100.0:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# try:\n",
    "#     app.run(main([None]))\n",
    "# except:\n",
    "#     print(\"exec end error\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71c52cf81b3ce176a2dee7a24d4a513c23ffb6ff815f0de53fd7e035b7d8234"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
