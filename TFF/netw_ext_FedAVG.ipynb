{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 12:01:20.943231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-08 12:01:20.943258: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tester/Desktop/TF/TFF', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/home/tester/venv/lib/python3.9/site-packages', '/home/tester/Desktop/federated/tensorflow_federated/examples/simple_fedavg']\n",
      "['/home/tester/Desktop/TF/TFF', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/home/tester/venv/lib/python3.9/site-packages', '/home/tester/Desktop/federated/tensorflow_federated/examples/simple_fedavg', '/home/tester/Desktop/federated/tensorflow_federated/examples/simple_fedavg']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "import collections\n",
    "\n",
    "from absl import app\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg\")\n",
    "print(sys.path)\n",
    "import simple_fedavg_tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "TOTAL_ROUNDS = 50 #NUMBER OF TOTAL TRAINING ROUNDS\n",
    "ROUNDS_PER_EVAL = 1 #HOW OFTEN TO EVALUATE\n",
    "TRAIN_CLIENTS_PER_ROUND = 2 #HOW MANY CLIENTS TO SAMPLE PER ROUND\n",
    "CLIENT_EPOCHS_PER_ROUND = 1 #NUMBER OF EPOCHS IN THE CLIENT TO TAKE PER ROUND\n",
    "BATCH_SIZE = 16 #BATCH SIZE USED ON THE CLIENT\n",
    "TEST_BATCH_SIZE = 128 #MINIBATCH SIZE OF TEST DATA\n",
    "SERVER_LEARNING_RATE = 1.0 #SERVER LEARNING RATE\n",
    "CLIENT_LEARNING_RATE = 0.1 #CLIENT LEARNING RATE\n",
    "NUM_CLIENTS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364743</th>\n",
       "      <td>36988</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63151</th>\n",
       "      <td>42100</td>\n",
       "      <td>7878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>46912</td>\n",
       "      <td>15600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67693</th>\n",
       "      <td>42104</td>\n",
       "      <td>15600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408076</th>\n",
       "      <td>53136</td>\n",
       "      <td>9197</td>\n",
       "      <td>132</td>\n",
       "      <td>1770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        src_port  dst_port  src_bytes  dst_bytes  missed_bytes  label\n",
       "364743     36988        80          0          0             0      1\n",
       "63151      42100      7878          0          0             0      0\n",
       "4667       46912     15600          0          0             0      0\n",
       "67693      42104     15600          0          0             0      0\n",
       "408076     53136      9197        132       1770             0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/TON_IoT-Datasets/Train_Test_datasets/Train_Test_Network_dataset/Train_Test_Network.csv\")\n",
    "df.head()\n",
    "reduced_df = df[[\"src_port\", \"dst_port\", \"src_bytes\", \"dst_bytes\", \"missed_bytes\" ,\"label\"]]\n",
    "\n",
    "df = reduced_df\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34930147513355586\n"
     ]
    }
   ],
   "source": [
    "# Percentage malware\n",
    "perc = len(df.loc[df['label']==1])/len(df)\n",
    "print(perc)\n",
    "\n",
    "# Balance classes??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#IID or NOIID? SPLIT DATA AMONG CLIENTS\n",
    "client_id = np.random.choice(range(NUM_CLIENTS), size=len(train), replace=True)\n",
    "#df['client_id'] = client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN: Create a dict where keys are client ids format for tff.simulation.datasets.TestClientData\n",
    "train_cl_dict = {}\n",
    "for id in range(NUM_CLIENTS):\n",
    "    tmp_train_df = train.loc[client_id == id]\n",
    "    tmp_train_dict = {name: np.array(value) \n",
    "                         for name, value in tmp_train_df.items()}\n",
    "    train_cl_dict[str(id)]=tmp_train_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine max_client_ds_size\n",
    "max_client_ds_size = -1\n",
    "for id in range(NUM_CLIENTS):\n",
    "    tmp_len = len(train.loc[client_id == id])\n",
    "    if(tmp_len > max_client_ds_size):\n",
    "        max_client_ds_size = tmp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "tmp_test_dict = {name: np.array(value)\n",
    "    for name, value in test.items()}\n",
    "test_cl_dict = {'0': tmp_test_dict}\n",
    "test_ds_size = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 12:01:24.130199: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-08 12:01:24.130229: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-08 12:01:24.130245: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debian): /proc/driver/nvidia/version does not exist\n",
      "2022-06-08 12:01:24.130458: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#CONVERT TO TFF DATASET\n",
    "#netw_ds = tf.data.Dataset.from_tensor_slices((netw_features_dict, netw_labels))\n",
    "#netw_ds = tf.data.Dataset.from_tensor_slices(netw_features_dict)\n",
    "train_netw_fd_ds = tff.simulation.datasets.TestClientData(train_cl_dict)\n",
    "test_netw_fd_ds = tff.simulation.datasets.TestClientData(test_cl_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FedAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(keras_model, test_dataset):\n",
    "  \"\"\"Evaluate the acurracy of a keras model on a test dataset.\"\"\"\n",
    "  metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "  for batch in test_dataset:\n",
    "    #DONT KNOW WHAT DOES\n",
    "    predictions = keras_model(batch['x'])\n",
    "    metric.update_state(y_true=batch['y'], y_pred=predictions)\n",
    "  return metric.result()\n",
    "\n",
    "\n",
    "def get_custom_dataset():\n",
    "  def element_fn(element):\n",
    "    features = tf.convert_to_tensor([element['src_port'],element['dst_port'],element['src_bytes'],element['dst_bytes'],element['missed_bytes']], dtype=tf.int64)\n",
    "    return collections.OrderedDict(\n",
    "      # tf.expand_dims? ADD MORE COLUMNS\n",
    "        x=features, y=element['label'])\n",
    "\n",
    "  def preprocess_train_dataset(dataset):\n",
    "    # Use buffer_size same as the maximum client dataset size,\n",
    "    return dataset.map(element_fn).shuffle(buffer_size=max_client_ds_size).repeat(\n",
    "        count=CLIENT_EPOCHS_PER_ROUND).batch(\n",
    "            BATCH_SIZE, drop_remainder=False)\n",
    "  def preprocess_test_dataset(dataset):\n",
    "    return dataset.map(element_fn).batch(\n",
    "        TEST_BATCH_SIZE, drop_remainder=False)\n",
    "  netw_train = train_netw_fd_ds.preprocess(preprocess_train_dataset)\n",
    "  netw_test = preprocess_test_dataset(\n",
    "      test_netw_fd_ds.create_tf_dataset_from_all_clients())\n",
    "  return netw_train, netw_test\n",
    "\n",
    "\n",
    "def create_fedavg_model(only_digits=True):\n",
    "  \"\"\"The CNN model used in https://arxiv.org/abs/1602.05629.\n",
    "\n",
    "  Args:\n",
    "    only_digits: If True, uses a final layer with 10 outputs, for use with the\n",
    "      digits only EMNIST dataset. If False, uses 62 outputs for the larger\n",
    "      dataset.\n",
    "\n",
    "  Returns:\n",
    "    An uncompiled `tf.keras.Model`.\n",
    "  \"\"\"\n",
    "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(5,)),\n",
    "    tf.keras.layers.Dense(8),\n",
    "    tf.keras.layers.Dense(8),\n",
    "    tf.keras.layers.Dense(8),\n",
    "    #tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
    "    tf.keras.layers.Softmax()\n",
    "    ])\n",
    "\n",
    "\n",
    "def server_optimizer_fn():\n",
    "  return tf.keras.optimizers.SGD(learning_rate=SERVER_LEARNING_RATE)\n",
    "\n",
    "\n",
    "def client_optimizer_fn():\n",
    "  return tf.keras.optimizers.SGD(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "  if len(argv) > 1:\n",
    "    raise app.UsageError('Too many command-line arguments.')\n",
    "  # If GPU is provided, TFF will by default use the first GPU like TF. The\n",
    "  # following lines will configure TFF to use multi-GPUs and distribute client\n",
    "  # computation on the GPUs. Note that we put server computatoin on CPU to avoid\n",
    "  # potential out of memory issue when a large number of clients is sampled per\n",
    "  # round. The client devices below can be an empty list when no GPU could be\n",
    "  # detected by TF.\n",
    "  client_devices = tf.config.list_logical_devices('GPU')\n",
    "  server_device = tf.config.list_logical_devices('CPU')[0]\n",
    "  tff.backends.native.set_local_python_execution_context(\n",
    "      server_tf_device=server_device, client_tf_devices=client_devices)\n",
    "  train_data, test_data = get_custom_dataset()\n",
    "\n",
    "  def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "    keras_model = create_fedavg_model(only_digits=True)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        input_spec=train_data.element_type_structure)\n",
    "\n",
    "  iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "      tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "  server_state = iterative_process.initialize()\n",
    "  # Keras model that represents the global model we'll evaluate test data on.\n",
    "  keras_model = create_fedavg_model(only_digits=True)\n",
    "  for round_num in range(TOTAL_ROUNDS):\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_data.client_ids,\n",
    "        size=TRAIN_CLIENTS_PER_ROUND,\n",
    "        replace=False)\n",
    "    sampled_train_data = [\n",
    "        train_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "    server_state, train_metrics = iterative_process.next(\n",
    "        server_state, sampled_train_data)\n",
    "    print(f'Round {round_num}')\n",
    "    print(f'\\tTraining metrics: {train_metrics}')\n",
    "    if round_num % ROUNDS_PER_EVAL == 0:\n",
    "      server_state.model.assign_weights_to(keras_model)\n",
    "      accuracy = evaluate(keras_model, test_data)\n",
    "      print(f'\\tValidation accuracy: {accuracy * 100.0:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.62819636), ('loss', 1.645773), ('num_examples', 14626), ('num_batches', 915)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 1\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6551795), ('loss', 1.6188245), ('num_examples', 14625), ('num_batches', 915)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 2\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65780395), ('loss', 1.6161996), ('num_examples', 14781), ('num_batches', 925)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 3\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6503034), ('loss', 1.6237006), ('num_examples', 14667), ('num_batches', 918)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 4\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64958423), ('loss', 1.6244196), ('num_examples', 14791), ('num_batches', 925)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 5\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6505416), ('loss', 1.623462), ('num_examples', 14863), ('num_batches', 930)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 6\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6440076), ('loss', 1.6299963), ('num_examples', 14652), ('num_batches', 917)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 7\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64107615), ('loss', 1.6329275), ('num_examples', 14719), ('num_batches', 921)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 8\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6411058), ('loss', 1.632898), ('num_examples', 14723), ('num_batches', 921)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 9\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65056217), ('loss', 1.6234416), ('num_examples', 14675), ('num_batches', 918)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 10\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6343588), ('loss', 1.6396449), ('num_examples', 14692), ('num_batches', 919)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 11\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.655142), ('loss', 1.6188619), ('num_examples', 14751), ('num_batches', 923)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 12\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64830995), ('loss', 1.6256938), ('num_examples', 14763), ('num_batches', 924)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 13\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65105885), ('loss', 1.6229452), ('num_examples', 14544), ('num_batches', 910)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 14\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6465523), ('loss', 1.6274512), ('num_examples', 14865), ('num_batches', 930)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 15\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6568955), ('loss', 1.6171085), ('num_examples', 14669), ('num_batches', 918)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 16\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6489119), ('loss', 1.6250918), ('num_examples', 14888), ('num_batches', 932)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 17\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6526766), ('loss', 1.6213269), ('num_examples', 14963), ('num_batches', 937)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 18\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64958423), ('loss', 1.6244196), ('num_examples', 14791), ('num_batches', 925)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 19\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64157313), ('loss', 1.632431), ('num_examples', 14519), ('num_batches', 909)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 20\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65929294), ('loss', 1.614711), ('num_examples', 14737), ('num_batches', 922)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 21\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65388495), ('loss', 1.6201189), ('num_examples', 14865), ('num_batches', 930)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 22\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6475863), ('loss', 1.6264174), ('num_examples', 14832), ('num_batches', 928)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 23\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65450037), ('loss', 1.6195037), ('num_examples', 14521), ('num_batches', 908)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 24\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6545723), ('loss', 1.6194314), ('num_examples', 14883), ('num_batches', 932)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 25\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65168923), ('loss', 1.6223146), ('num_examples', 14711), ('num_batches', 921)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 26\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6508045), ('loss', 1.6231995), ('num_examples', 14605), ('num_batches', 914)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 27\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6547845), ('loss', 1.6192194), ('num_examples', 14756), ('num_batches', 924)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 28\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6397154), ('loss', 1.6342883), ('num_examples', 14755), ('num_batches', 923)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 29\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6539856), ('loss', 1.6200182), ('num_examples', 14615), ('num_batches', 915)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 30\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6442998), ('loss', 1.6297038), ('num_examples', 14903), ('num_batches', 932)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 31\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6383558), ('loss', 1.6356479), ('num_examples', 14694), ('num_batches', 919)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 32\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6437716), ('loss', 1.6302321), ('num_examples', 14763), ('num_batches', 923)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 33\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6467343), ('loss', 1.6272696), ('num_examples', 14683), ('num_batches', 919)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 34\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6523493), ('loss', 1.6216544), ('num_examples', 14877), ('num_batches', 931)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 35\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65297794), ('loss', 1.6210258), ('num_examples', 14708), ('num_batches', 921)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 36\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64958316), ('loss', 1.6244208), ('num_examples', 14634), ('num_batches', 916)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 37\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6437716), ('loss', 1.6302321), ('num_examples', 14763), ('num_batches', 923)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 38\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6492218), ('loss', 1.6247821), ('num_examples', 14713), ('num_batches', 921)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 39\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6537892), ('loss', 1.6202146), ('num_examples', 14858), ('num_batches', 930)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 40\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6526323), ('loss', 1.6213713), ('num_examples', 14892), ('num_batches', 932)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 41\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6536873), ('loss', 1.6203166), ('num_examples', 14767), ('num_batches', 924)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 42\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.64632475), ('loss', 1.6276792), ('num_examples', 14584), ('num_batches', 913)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 43\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6377173), ('loss', 1.6362861), ('num_examples', 14842), ('num_batches', 928)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 44\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65108156), ('loss', 1.622922), ('num_examples', 14886), ('num_batches', 931)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 45\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6503034), ('loss', 1.6237006), ('num_examples', 14667), ('num_batches', 918)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 46\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6416252), ('loss', 1.6323787), ('num_examples', 14669), ('num_batches', 918)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 47\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.65611494), ('loss', 1.6178887), ('num_examples', 15037), ('num_batches', 941)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 48\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6605746), ('loss', 1.6134291), ('num_examples', 14828), ('num_batches', 928)])\n",
      "\tValidation accuracy: 64.79%\n",
      "Round 49\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6531541), ('loss', 1.6208496), ('num_examples', 14949), ('num_batches', 935)])\n",
      "\tValidation accuracy: 64.79%\n",
      "exec end error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FATAL Flags parsing error: Unknown command line flag 'ip'\n",
      "Pass --helpshort or --helpfull to see help on flags.\n"
     ]
    }
   ],
   "source": [
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "try:\n",
    "    app.run(main([None]))\n",
    "except:\n",
    "    print(\"exec end error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71c52cf81b3ce176a2dee7a24d4a513c23ffb6ff815f0de53fd7e035b7d8234"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
