{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 04:07:06.372726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-24 04:07:06.372759: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "#from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"../datasets/TON_IoT-Datasets/Train_Test_datasets/Train_Test_IoT_dataset/Train_Test_IoT_Modbus.csv\")\n",
    "columns = range(3,8)\n",
    "df = dataframe.iloc[:, columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT REAL, USING ALL THE DATASET - NORMALIZATION MUST BE DONE LOCALLY OR TAKING INTO ACCOUNT CLIENT ROW\n",
    "df_norm = df.copy()\n",
    "df_norm = df_norm.iloc[:, range(4)]\n",
    "for cl in df_norm.columns:\n",
    "    df_norm[cl].astype('float32')\n",
    "    min = np.min(df_norm[cl])\n",
    "    max = np.max(df_norm[cl])\n",
    "    df_norm[cl] = (df_norm[cl] - min) / (max - min)\n",
    "\n",
    "df_norm = pd.concat([df_norm, df.iloc[:,-1]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 1\n",
    "client_id_colname = 'clis'\n",
    "\n",
    "#IID or NOIID?\n",
    "choices = np.random.choice(range(NUM_CLIENTS), size=len(df_norm), replace=True)\n",
    "\n",
    "dcli = {client_id_colname: choices}\n",
    "dfcli = pd.DataFrame(data=dcli)\n",
    "\n",
    "df = pd.concat([df_norm, dfcli], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AUGMENTATION\n",
    "#df = df.sample(300000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.RepeatDataset'>\n",
      "{'FC1_Read_Input_Register': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.23794772], dtype=float32)>, 'FC2_Read_Discrete_Value': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.95381093], dtype=float32)>, 'FC3_Read_Holding_Register': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.99769557], dtype=float32)>, 'FC4_Read_Coil': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.41250342], dtype=float32)>, 'label': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, 'clis': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 04:07:10.132772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-24 04:07:10.132806: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-24 04:07:10.132824: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debian): /proc/driver/nvidia/version does not exist\n",
      "2022-05-24 04:07:10.133065: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#df = pd.read_csv(csv_url, na_values=(\"?\",))\n",
    "\n",
    "SHUFFLE_BUFFER = 1000\n",
    "NUM_EPOCHS = 1\n",
    "# split client id into train and test clients\n",
    "client_ids = df[client_id_colname].unique()\n",
    "train_client_ids = pd.DataFrame(client_ids).sample(frac=0.8).values.tolist()\n",
    "test_client_ids = [[x] for x in client_ids if x not in train_client_ids]\n",
    "\n",
    "def create_tf_dataset_for_client_fn(client_id):\n",
    "  # a function which takes a client_id and returns a\n",
    "  # tf.data.Dataset for that client\n",
    "  client_data = df[df[client_id_colname] == client_id[0]]\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(client_data.fillna('').to_dict(\"list\"))\n",
    "  dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).repeat(NUM_EPOCHS)\n",
    "  return dataset\n",
    "\n",
    "train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=train_client_ids,\n",
    "        serializable_dataset_fn = create_tf_dataset_for_client_fn\n",
    "        #create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn\n",
    "    )\n",
    "\n",
    "test_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "         client_ids=test_client_ids,\n",
    "         serializable_dataset_fn = create_tf_dataset_for_client_fn\n",
    "         #create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn\n",
    "     )\n",
    "\n",
    "example_dataset = train_data.create_tf_dataset_for_client(\n",
    "        train_data.client_ids[0]\n",
    "    )\n",
    "\n",
    "print(type(example_dataset))\n",
    "example_element = iter(example_dataset).next()\n",
    "print(example_element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "  def batch_format_fn(element):\n",
    "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
    "    return (tf.reshape([element['FC1_Read_Input_Register'], element['FC2_Read_Discrete_Value'], element['FC3_Read_Holding_Register'], element['FC4_Read_Coil']], [-1, 4]),\n",
    "            tf.reshape(element['label'], [-1, 1]))\n",
    "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = sorted(train_data.client_ids)[:NUM_CLIENTS]\n",
    "federated_train_data = [preprocess(train_data.create_tf_dataset_for_client(x))\n",
    "  for x in client_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_keras_model():\n",
    "#  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "#  return tf.keras.models.Sequential([\n",
    "#      tf.keras.layers.Input(shape=(4,)),\n",
    "#      tf.keras.layers.Dense(8),\n",
    "#      tf.keras.layers.Dense(10),\n",
    "#      tf.keras.layers.Dense(8),\n",
    "#      #tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
    "#      tf.keras.layers.Softmax(),\n",
    "#  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "  #initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(4,)),\n",
    "      #tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      #tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "      tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=federated_train_data[0].element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_fn():\n",
    "  model = model_fn()\n",
    "  return model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_fn(server_weights, federated_dataset):\n",
    "  # Broadcast the server weights to the clients.\n",
    "  server_weights_at_client = broadcast(server_weights)\n",
    "\n",
    "  # Each client computes their updated weights.\n",
    "  client_weights = client_update(federated_dataset, server_weights_at_client)\n",
    "\n",
    "  # The server averages these updates.\n",
    "  mean_client_weights = mean(client_weights)\n",
    "\n",
    "  # The server updates its model.\n",
    "  server_weights = server_update(mean_client_weights)\n",
    "\n",
    "  return server_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def client_update(model, dataset, server_weights, client_optimizer):\n",
    "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
    "  # Initialize the client model with the current server weights.\n",
    "  client_weights = model.trainable_variables\n",
    "  # Assign the server weights to the client model.\n",
    "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
    "                        client_weights, server_weights)\n",
    "\n",
    "  # Use the client_optimizer to update the local model.\n",
    "  for batch in dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      # Compute a forward pass on the batch of data\n",
    "      outputs = model.forward_pass(batch)\n",
    "\n",
    "    # Compute the corresponding gradient\n",
    "    grads = tape.gradient(outputs.loss, client_weights)\n",
    "    grads_and_vars = zip(grads, client_weights)\n",
    "\n",
    "    # Apply the gradient using a client optimizer.\n",
    "    client_optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "  return client_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def server_update(model, mean_client_weights):\n",
    "  \"\"\"Updates the server model weights as the average of the client model weights.\"\"\"\n",
    "  model_weights = model.trainable_variables\n",
    "  # Assign the mean client weights to the server model.\n",
    "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
    "                        model_weights, mean_client_weights)\n",
    "  return model_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation\n",
    "def server_init():\n",
    "  model = model_fn()\n",
    "  return model.trainable_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation\n",
    "def initialize_fn():\n",
    "  return tff.federated_value(server_init(), tff.SERVER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "whimsy_model = model_fn()\n",
    "tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<float32[?,4],int32[?,1]>*'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tf_dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_type = server_init.type_signature.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<float32[4,64],float32[64],float32[64,32],float32[32],float32[32,16],float32[16],float32[16,8],float32[8],float32[8,16],float32[16],float32[16,32],float32[32],float32[32,64],float32[64]>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model_weights_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(tf_dataset_type, model_weights_type)\n",
    "def client_update_fn(tf_dataset, server_weights):\n",
    "  model = model_fn()\n",
    "  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "  return client_update(model, tf_dataset, server_weights, client_optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(model_weights_type)\n",
    "def server_update_fn(mean_client_weights):\n",
    "  model = model_fn()\n",
    "  return server_update(model, mean_client_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n",
    "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
    "def next_fn(server_weights, federated_dataset):\n",
    "  # Broadcast the server weights to the clients.\n",
    "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
    "\n",
    "  # Each client computes their updated weights.\n",
    "  client_weights = tff.federated_map(\n",
    "      client_update_fn, (federated_dataset, server_weights_at_client))\n",
    "\n",
    "  # The server averages these updates.\n",
    "  mean_client_weights = tff.federated_mean(client_weights)\n",
    "\n",
    "  # The server updates its model.\n",
    "  server_weights = tff.federated_map(server_update_fn, mean_client_weights)\n",
    "\n",
    "  return server_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_algorithm = tff.templates.IterativeProcess(\n",
    "    initialize_fn=initialize_fn,\n",
    "    next_fn=next_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( -> <float32[4,64],float32[64],float32[64,32],float32[32],float32[32,16],float32[16],float32[16,8],float32[8],float32[8,16],float32[16],float32[16,32],float32[32],float32[32,64],float32[64]>@SERVER)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(federated_algorithm.initialize.type_signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<server_weights=<float32[4,64],float32[64],float32[64,32],float32[32],float32[32,16],float32[16],float32[16,8],float32[8],float32[8,16],float32[16],float32[16,32],float32[32],float32[32,64],float32[64]>@SERVER,federated_dataset={<float32[?,4],int32[?,1]>*}@CLIENTS> -> <float32[4,64],float32[64],float32[64,32],float32[32],float32[32,16],float32[16],float32[16,8],float32[8],float32[8,16],float32[16],float32[16,32],float32[32],float32[32,64],float32[64]>@SERVER)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(federated_algorithm.next.type_signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = sorted(test_data.client_ids)[:NUM_CLIENTS]\n",
    "federated_test_data = [preprocess(test_data.create_tf_dataset_for_client(x))\n",
    "  for x in client_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(server_state):\n",
    "  keras_model = create_keras_model()\n",
    "  keras_model.compile(\n",
    "      optimizer = tf.optimizers.Adam(),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]#,tf.keras.metrics.BinaryAccuracy()]  \n",
    "  )\n",
    "  keras_model.set_weights(server_state)\n",
    "\n",
    "  #JUST EVALUATING IN ONE CLIENTS DATA FIX IT\n",
    "  keras_model.evaluate(federated_test_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5133/5133 [==============================] - 4s 729us/step - loss: 4.1759 - sparse_categorical_accuracy: 1.9482e-04\n"
     ]
    }
   ],
   "source": [
    "server_state = federated_algorithm.initialize()\n",
    "evaluate(server_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for round in range(15):\n",
    "  server_state = federated_algorithm.next(server_state, federated_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5133/5133 [==============================] - 4s 779us/step - loss: 1.0633 - sparse_categorical_accuracy: 0.6750\n"
     ]
    }
   ],
   "source": [
    "evaluate(server_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71c52cf81b3ce176a2dee7a24d4a513c23ffb6ff815f0de53fd7e035b7d8234"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
