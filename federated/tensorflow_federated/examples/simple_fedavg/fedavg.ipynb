{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/home/tester/venv/lib/python3.9/site-packages', '/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg', '/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg', '/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import functools\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/tester/Desktop/TF/federated/tensorflow_federated/examples/simple_fedavg\")\n",
    "print(sys.path)\n",
    "\n",
    "import simple_fedavg_tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "TOTAL_ROUNDS = 50 #NUMBER OF TOTAL TRAINING ROUNDS\n",
    "ROUNDS_PER_EVAL = 1 #HOW OFTEN TO EVALUATE\n",
    "TRAIN_CLIENTS_PER_ROUND = 2 #HOW MANY CLIENTS TO SAMPLE PER ROUND\n",
    "CLIENT_EPOCHS_PER_ROUND = 1 #NUMBER OF EPOCHS IN THE CLIENT TO TAKE PER ROUND\n",
    "BATCH_SIZE = 16 #BATCH SIZE USED ON THE CLIENT\n",
    "TEST_BATCH_SIZE = 128 #MINIBATCH SIZE OF TEST DATA\n",
    "SERVER_LEARNING_RATE = 1.0 #SERVER LEARNING RATE\n",
    "CLIENT_LEARNING_RATE = 0.1 #CLIENT LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(keras_model, test_dataset):\n",
    "  \"\"\"Evaluate the acurracy of a keras model on a test dataset.\"\"\"\n",
    "  metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "  for batch in test_dataset:\n",
    "    predictions = keras_model(batch['x'])\n",
    "    metric.update_state(y_true=batch['y'], y_pred=predictions)\n",
    "  return metric.result()\n",
    "\n",
    "\n",
    "def get_emnist_dataset():\n",
    "  \"\"\"Loads and preprocesses the EMNIST dataset.\n",
    "\n",
    "  Returns:\n",
    "    A `(emnist_train, emnist_test)` tuple where `emnist_train` is a\n",
    "    `tff.simulation.datasets.ClientData` object representing the training data\n",
    "    and `emnist_test` is a single `tf.data.Dataset` representing the test data\n",
    "    of all clients.\n",
    "  \"\"\"\n",
    "  emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(\n",
    "      only_digits=True)\n",
    "  def element_fn(element):\n",
    "    return collections.OrderedDict(\n",
    "        x=tf.expand_dims(element['pixels'], -1), y=element['label'])\n",
    "\n",
    "  def preprocess_train_dataset(dataset):\n",
    "    # Use buffer_size same as the maximum client dataset size,\n",
    "    # 418 for Federated EMNIST\n",
    "    return dataset.map(element_fn).shuffle(buffer_size=418).repeat(\n",
    "        count=CLIENT_EPOCHS_PER_ROUND).batch(\n",
    "            BATCH_SIZE, drop_remainder=False)\n",
    "  def preprocess_test_dataset(dataset):\n",
    "    return dataset.map(element_fn).batch(\n",
    "        TEST_BATCH_SIZE, drop_remainder=False)\n",
    "  emnist_train = emnist_train.preprocess(preprocess_train_dataset)\n",
    "  emnist_test = preprocess_test_dataset(\n",
    "      emnist_test.create_tf_dataset_from_all_clients())\n",
    "  return emnist_train, emnist_test\n",
    "\n",
    "\n",
    "def create_original_fedavg_cnn_model(only_digits=True):\n",
    "  \"\"\"The CNN model used in https://arxiv.org/abs/1602.05629.\n",
    "\n",
    "  Args:\n",
    "    only_digits: If True, uses a final layer with 10 outputs, for use with the\n",
    "      digits only EMNIST dataset. If False, uses 62 outputs for the larger\n",
    "      dataset.\n",
    "\n",
    "  Returns:\n",
    "    An uncompiled `tf.keras.Model`.\n",
    "  \"\"\"\n",
    "  data_format = 'channels_last'\n",
    "  input_shape = [28, 28, 1]\n",
    "  max_pool = functools.partial(\n",
    "      tf.keras.layers.MaxPooling2D,\n",
    "      pool_size=(2, 2),\n",
    "      padding='same',\n",
    "      data_format=data_format)\n",
    "  conv2d = functools.partial(\n",
    "      tf.keras.layers.Conv2D,\n",
    "      kernel_size=5,\n",
    "      padding='same',\n",
    "      data_format=data_format,\n",
    "      activation=tf.nn.relu)\n",
    "  model = tf.keras.models.Sequential([\n",
    "      conv2d(filters=32, input_shape=input_shape),\n",
    "      max_pool(),\n",
    "      conv2d(filters=64),\n",
    "      max_pool(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "      tf.keras.layers.Dense(10 if only_digits else 62),\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "\n",
    "def server_optimizer_fn():\n",
    "  return tf.keras.optimizers.SGD(learning_rate=SERVER_LEARNING_RATE)\n",
    "\n",
    "\n",
    "def client_optimizer_fn():\n",
    "  return tf.keras.optimizers.SGD(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "  if len(argv) > 1:\n",
    "    raise app.UsageError('Too many command-line arguments.')\n",
    "  # If GPU is provided, TFF will by default use the first GPU like TF. The\n",
    "  # following lines will configure TFF to use multi-GPUs and distribute client\n",
    "  # computation on the GPUs. Note that we put server computatoin on CPU to avoid\n",
    "  # potential out of memory issue when a large number of clients is sampled per\n",
    "  # round. The client devices below can be an empty list when no GPU could be\n",
    "  # detected by TF.\n",
    "  client_devices = tf.config.list_logical_devices('GPU')\n",
    "  server_device = tf.config.list_logical_devices('CPU')[0]\n",
    "  tff.backends.native.set_local_python_execution_context(\n",
    "      server_tf_device=server_device, client_tf_devices=client_devices)\n",
    "  train_data, test_data = get_emnist_dataset()\n",
    "\n",
    "  def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "    keras_model = create_original_fedavg_cnn_model(only_digits=True)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        input_spec=train_data.element_type_structure)\n",
    "\n",
    "  iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "      tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "  server_state = iterative_process.initialize()\n",
    "  # Keras model that represents the global model we'll evaluate test data on.\n",
    "  keras_model = create_original_fedavg_cnn_model(only_digits=True)\n",
    "  for round_num in range(TOTAL_ROUNDS):\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_data.client_ids,\n",
    "        size=TRAIN_CLIENTS_PER_ROUND,\n",
    "        replace=False)\n",
    "    sampled_train_data = [\n",
    "        train_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "    server_state, train_metrics = iterative_process.next(\n",
    "        server_state, sampled_train_data)\n",
    "    print(f'Round {round_num}')\n",
    "    print(f'\\tTraining metrics: {train_metrics}')\n",
    "    if round_num % ROUNDS_PER_EVAL == 0:\n",
    "      server_state.model.assign_weights_to(keras_model)\n",
    "      accuracy = evaluate(keras_model, test_data)\n",
    "      print(f'\\tValidation accuracy: {accuracy * 100.0:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch asyncio to allow nested event loops. If not used, runtime error in Jupyter NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 12:12:32.954908: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-08 12:12:32.954929: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-08 12:12:32.954946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debian): /proc/driver/nvidia/version does not exist\n",
      "2022-06-08 12:12:32.955162: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.088785045), ('loss', 2.3499544), ('num_examples', 214), ('num_batches', 14)])\n",
      "\tValidation accuracy: 11.66%\n",
      "Round 1\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.12682927), ('loss', 2.3127558), ('num_examples', 205), ('num_batches', 14)])\n",
      "\tValidation accuracy: 10.90%\n",
      "Round 2\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.07272727), ('loss', 2.307422), ('num_examples', 220), ('num_batches', 15)])\n",
      "\tValidation accuracy: 10.45%\n",
      "Round 3\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.13020833), ('loss', 2.2984877), ('num_examples', 192), ('num_batches', 13)])\n",
      "\tValidation accuracy: 13.44%\n",
      "Round 4\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.15757576), ('loss', 2.288634), ('num_examples', 165), ('num_batches', 12)])\n",
      "\tValidation accuracy: 19.23%\n",
      "Round 5\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.15668203), ('loss', 2.2967598), ('num_examples', 217), ('num_batches', 15)])\n",
      "\tValidation accuracy: 14.86%\n",
      "Round 6\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.13559322), ('loss', 2.2758536), ('num_examples', 177), ('num_batches', 12)])\n",
      "\tValidation accuracy: 28.85%\n",
      "Round 7\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.27804878), ('loss', 2.2496927), ('num_examples', 205), ('num_batches', 14)])\n",
      "\tValidation accuracy: 20.62%\n",
      "Round 8\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.1368421), ('loss', 2.2435195), ('num_examples', 190), ('num_batches', 13)])\n",
      "\tValidation accuracy: 10.13%\n",
      "Round 9\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.25853658), ('loss', 2.183734), ('num_examples', 205), ('num_batches', 13)])\n",
      "\tValidation accuracy: 36.01%\n",
      "Round 10\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.32380953), ('loss', 2.113204), ('num_examples', 210), ('num_batches', 14)])\n",
      "\tValidation accuracy: 16.81%\n",
      "Round 11\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.26940638), ('loss', 2.1085842), ('num_examples', 219), ('num_batches', 15)])\n",
      "\tValidation accuracy: 10.61%\n",
      "Round 12\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.2985782), ('loss', 2.0294883), ('num_examples', 211), ('num_batches', 15)])\n",
      "\tValidation accuracy: 22.41%\n",
      "Round 13\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.35051546), ('loss', 1.9818368), ('num_examples', 194), ('num_batches', 13)])\n",
      "\tValidation accuracy: 57.28%\n",
      "Round 14\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.58469945), ('loss', 1.468858), ('num_examples', 183), ('num_batches', 12)])\n",
      "\tValidation accuracy: 56.67%\n",
      "Round 15\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.45327103), ('loss', 1.6190488), ('num_examples', 214), ('num_batches', 15)])\n",
      "\tValidation accuracy: 56.17%\n",
      "Round 16\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.57476634), ('loss', 1.372485), ('num_examples', 214), ('num_batches', 14)])\n",
      "\tValidation accuracy: 50.46%\n",
      "Round 17\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.58549225), ('loss', 1.3278711), ('num_examples', 193), ('num_batches', 13)])\n",
      "\tValidation accuracy: 39.67%\n",
      "Round 18\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.5882353), ('loss', 1.3392379), ('num_examples', 187), ('num_batches', 13)])\n",
      "\tValidation accuracy: 66.72%\n",
      "Round 19\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.7121951), ('loss', 0.9655875), ('num_examples', 205), ('num_batches', 14)])\n",
      "\tValidation accuracy: 53.17%\n",
      "Round 20\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.5939086), ('loss', 1.1052514), ('num_examples', 197), ('num_batches', 14)])\n",
      "\tValidation accuracy: 48.20%\n",
      "Round 21\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6651376), ('loss', 1.0967915), ('num_examples', 218), ('num_batches', 15)])\n",
      "\tValidation accuracy: 66.61%\n",
      "Round 22\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8063063), ('loss', 0.6449929), ('num_examples', 222), ('num_batches', 15)])\n",
      "\tValidation accuracy: 68.97%\n",
      "Round 23\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8306878), ('loss', 0.68817556), ('num_examples', 189), ('num_batches', 12)])\n",
      "\tValidation accuracy: 66.99%\n",
      "Round 24\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.84689), ('loss', 0.56105894), ('num_examples', 209), ('num_batches', 14)])\n",
      "\tValidation accuracy: 72.11%\n",
      "Round 25\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.8597285), ('loss', 0.41389593), ('num_examples', 221), ('num_batches', 14)])\n",
      "\tValidation accuracy: 78.53%\n",
      "Round 26\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.6381909), ('loss', 1.2054064), ('num_examples', 199), ('num_batches', 13)])\n",
      "\tValidation accuracy: 77.88%\n",
      "Round 27\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.83913046), ('loss', 0.5286269), ('num_examples', 230), ('num_batches', 16)])\n",
      "\tValidation accuracy: 62.54%\n",
      "Round 28\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.775), ('loss', 0.6585872), ('num_examples', 200), ('num_batches', 14)])\n",
      "\tValidation accuracy: 79.26%\n",
      "Round 29\n",
      "\tTraining metrics: OrderedDict([('sparse_categorical_accuracy', 0.85022026), ('loss', 0.44243866), ('num_examples', 227), ('num_batches', 16)])\n",
      "exec end error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    app.run(main([None]))\n",
    "except:\n",
    "    print(\"exec end error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71c52cf81b3ce176a2dee7a24d4a513c23ffb6ff815f0de53fd7e035b7d8234"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
